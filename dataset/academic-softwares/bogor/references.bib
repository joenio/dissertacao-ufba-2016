@INPROCEEDINGS{6200090,
  author={M. Kim and Y. Kim and G. Rothermel},
  booktitle={2012 IEEE Fifth International Conference on Software Testing, Verification and Validation},
  title={A Scalable Distributed Concolic Testing Approach: An Empirical Evaluation},
  year={2012},
  pages={340-349},
  abstract={Although testing is a standard method for improving the quality of software, conventional testing methods often fail to detect faults. Concolic testing attempts to remedy this by automatically generating test cases to explore execution paths in a program under test, helping testers achieve greater coverage of program behavior in a more automated fashion. Concolic testing, however, consumes a significant amount of computing time to explore execution paths, which is an obstacle toward its practical application. To address this limitation, we have developed a scalable distributed concolic testing framework that utilizes large numbers of computing nodes to generate test cases in a scalable manner. In this paper, we present the results of an empirical study that shows that the proposed framework can achieve a several orders-of-magnitude increase in test case generation speed compared to the original concolic approach, and also demonstrates clear potential for scalability.},
  keywords={program testing;software fault tolerance;software quality;automatic test case generation;fault detection;orders-of-magnitude;scalable distributed concolic testing approach;software quality improvement method;software testing methods;Concrete;Java;Partitioning algorithms;Scalability;Servers;Testing;Virtual machining},
  doi={10.1109/ICST.2012.114},
  ISSN={2159-4848},
  month={April},
}

@INPROCEEDINGS{4221616,
  author={M. B. Dwyer and J. Hatcliff and R. Robby and C. S. Pasareanu and W. Visser},
  booktitle={Future of Software Engineering, 2007. FOSE '07},
  title={Formal Software Analysis Emerging Trends in Software Model Checking},
  year={2007},
  pages={120-136},
  abstract={The study of methodologies and techniques to produce correct software has been active for four decades. During this period, researchers have developed and investigated a wide variety of approaches, but techniques based on mathematical modeling of program behavior have been a particular focus since they offer the promise of both finding errors and assuring important program properties. The past fifteen years have seen a marked and accelerating shift towards algorithmic formal reasoning about program behavior - we refer to these as formal software analysis. In this paper, we define formal software analyses as having several important properties that distinguish them from other forms of software analysis. We describe three foundational formal software analyses, but focus on the adaptation of model checking to reason about software. We review emerging trends in software model checking and identify future directions that promise to significantly improve its cost-effectiveness.},
  keywords={software engineering;algorithmic formal reasoning;formal software analysis;program behavior;software model checking;Algorithm design and analysis;Computational Intelligence Society;Computer languages;Computer science;Embedded software;Information analysis;NASA;Object oriented modeling;Software algorithms;Software engineering},
  doi={10.1109/FOSE.2007.6},
  month={May},
}

@INPROCEEDINGS{7886898,
  author={E. F. Rizzi and S. Elbaum and M. B. Dwyer},
  booktitle={2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)},
  title={On the Techniques We Create, the Tools We Build, and Their Misalignments: A Study of KLEE},
  year={2016},
  pages={132-143},
  abstract={Our community constantly pushes the state-of-the-art by introducing “new” techniques. These techniques often build on top of, and are compared against, existing systems that realize previously published techniques. The underlying assumption is that existing systems correctly represent the techniques they implement. This pa- per examines that assumption through a study of KLEE, a popular and well-cited tool in our community. We briefly describe six improvements we made to KLEE, none of which can be considered “new” techniques, that provide order-of-magnitude performance gains. Given these improvements, we then investigate how the results and conclusions of a sample of papers that cite KLEE are affected. Our findings indicate that the strong emphasis on introducing “new” techniques may lead to wasted effort, missed opportunities for progress, an accretion of artifact complexity, and questionable research conclusions (in our study, 27% of the papers that depend on KLEE can be questioned). We conclude by revisiting initiatives that may help to realign the incentives to better support the foundations on which we build.},
  keywords={software engineering;KLEE tool;artifact complexity;performance gain;software techniques;Buildings;Complexity theory;Computer bugs;Engineering profession;Optimization;Software;Software engineering;Research incentives;replication;research tools and infrastructure},
  doi={10.1145/2884781.2884835},
  month={May},
}

@INPROCEEDINGS{7027430,
  author={X. Fu and Z. Chen and Y. Zhang and C. Huang and W. Dong and J. Wang},
  booktitle={2015 IEEE 16th International Symposium on High Assurance Systems Engineering},
  title={MPISE: Symbolic Execution of MPI Programs},
  year={2015},
  pages={181-188},
  abstract={Message Passing Interfaces (MPI) plays an important role in parallel computing. Many parallel applications are implemented as MPI programs. The existing methods of bug detection for MPI programs have the shortage of providing both input and non-determinism coverage, leading to missed bugs. In this paper, we employ symbolic execution to ensure the input coverage, and propose an on-the-fly schedule algorithm to reduce the interleaving explorations for non-determinism coverage, while ensuring the soundness and completeness. We have implemented our approach as a tool, called MPISE, which can automatically detect the deadlock and runtime bugs in MPI programs. The results of the experiments on benchmark programs and real world MPI programs indicate that MPISE finds bugs effectively and efficiently. In addition, our tool also provides diagnostic information and replay mechanism to help understand bugs.},
  keywords={message passing;parallel programming;program debugging;program diagnostics;scheduling;system recovery;MPI programs;MPISE;automatic deadlock detection;benchmark programs;bug finding;bug understanding;diagnostic information;input coverage;interleaving exploration reduction;message passing interfaces;nondeterminism coverage;on-the-fly schedule algorithm;parallel applications;parallel computing;replay mechanism;runtime bug detection;symbolic execution;Computer bugs;Runtime;Scheduling;Switches;Synchronization;System recovery;Testing;Message Passing Interfaces;deadlock detection;symbolic execution},
  doi={10.1109/HASE.2015.35},
  ISSN={1530-2059},
  month={Jan},
}

@INPROCEEDINGS{6032591,
  author={C. Cadar and P. Godefroid and S. Khurshid and C. S. Pasareanu and K. Sen and N. Tillmann and W. Visser},
  booktitle={2011 33rd International Conference on Software Engineering (ICSE)},
  title={Symbolic execution for software testing in practice: preliminary assessment},
  year={2011},
  pages={1066-1071},
  abstract={We present results for the "Impact Project Focus Area" on the topic of symbolic execution as used in software testing. Symbolic execution is a program analysis technique introduced in the 70s that has received renewed interest in recent years, due to algorithmic advances and increased availability of computational power and constraint solving technology. We review classical symbolic execution and some modern extensions such as generalized symbolic execution and dynamic test generation. We also give a preliminary assessment of the use in academia, research labs, and industry.},
  keywords={program testing;computational power;preliminary assessment;program analysis;software testing;symbolic execution;Computer bugs;Concrete;Java;Security;Software;Testing;Unified modeling language;dynamic test generation;generalized symbolic execution},
  doi={10.1145/1985793.1985995},
  ISSN={0270-5257},
  month={May},
}

@INPROCEEDINGS{6405256,
  author={C. R. Rupakheti and D. Hou},
  booktitle={2012 28th IEEE International Conference on Software Maintenance (ICSM)},
  title={Finding errors from reverse-engineered equality models using a constraint solver},
  year={2012},
  pages={77-86},
  abstract={Java objects are required to honor an equality contract in order to participate in standard collection data structures such as List, Set, and Map. In practice, the implementation of equality can be error prone, resulting in subtle bugs. We present a checker called EQ that is designed to automatically detect such equality implementation bugs. The key to EQ is the automated extraction of a logical model of equality from Java code, which is then checked, using Alloy Analyzer, for contract conformance. We have evaluated EQ on four open-source, production code bases in terms of both scalability and usefulness. We discuss in detail the detected problems, their root causes, and the reasons for false alarms.},
  keywords={Java;data structures;formal verification;program debugging;reverse engineering;Alloy Analyzer;EQ checker;Java object;constraint solver;contract conformance;equality contract;equality implementation bug;list data structure;map data structure;reverse-engineered equality model;scalability term;set data structure;usefulness term;Abstracts;Arrays;Detectors;Java;Metals;Standards;Testing;Abstraction Recognition;Alloy;Java;Model Finding;Object Equality;Path-Based Analysis;Soot},
  doi={10.1109/ICSM.2012.6405256},
  ISSN={1063-6773},
  month={Sept},
}

@INPROCEEDINGS{4685803,
  author={C. Gladisch},
  booktitle={2008 Sixth IEEE International Conference on Software Engineering and Formal Methods},
  title={Verification-Based Test Case Generation for Full Feasible Branch Coverage},
  year={2008},
  pages={159-168},
  abstract={The goal of this work is to improve the testing of programs that contain loops and complex methods. We achieve this goal with verification-based testing, which is a technique that can generate test cases not only from source code but also from loop invariants and method specifications provided by the user. These test cases ensure the execution of interesting program paths that are likely to be missed by existing testing techniques that are based on symbolic program execution. These techniques would require an exhaustive inspection of all execution paths, which is hard to achieve in presence of complex methods and impossible if loops are involved. Verification-based testing takes a different approach.},
  keywords={formal specification;program control structures;program verification;exhaustive inspection;full feasible branch coverage;loop invariant;program testing;symbolic program execution;verification-based test case generation;Arithmetic;Calculus;Computer science;Concrete;Inspection;Java;Logic testing;Programming;Software engineering;Software testing;Branch Coverage;Dynamic Logic;Java;Precondition;Specification-based Testing;Verification-based Testing;White-box Testing},
  doi={10.1109/SEFM.2008.22},
  ISSN={1551-0255},
  month={Nov},
}

@INPROCEEDINGS{6285773,
  author={N. Aleb and S. Kechid},
  booktitle={2012 International Conference on Communications and Information Technology (ICCIT)},
  title={Path coverage testing in the cloud},
  year={2012},
  pages={118-123},
  abstract={The aim of this paper is to present a new method for automated software testing as a cloud computing service. Unlike actual testing services, our goal is to provide a fully automated testing without human involvement from the service user's or provider's side. We use a program modeling allowing an easy symbolic execution and a scalable parallelization of the testing. Programs are divided into several parts assigned to different nodes (Workers) of the cloud. A particular node (Coordinator) allocates tasks to Workers and collects the final results.},
  keywords={cloud computing;program testing;resource allocation;automated software testing;coordinator;path coverage testing;program modeling;symbolic execution;task allocation;testing scalable parallelization;workers;Cloud computing;Computational modeling;Concrete;Data models;Software testing;Cloud Computing;Software Testing;Symbolic Execution;Testing as a Service},
  doi={10.1109/ICCITechnol.2012.6285773},
  month={June},
}

@INPROCEEDINGS{1691665,
  author={M. B. Dwyer and J. Hatcliff},
  booktitle={Testing: Academic Industrial Conference - Practice And Research Techniques (TAIC PART'06)},
  title={Bogor: A Flexible Framework for Creating Software Model Checkers},
  year={2006},
  pages={3-22},
  abstract={Model checking has proven to be an effective technology for verification and debugging in hardware and more recently in software domains. With the proliferation of multi-core architectures and a greater emphasis on distributed computing, model checking is an increasingly important software quality assurance technique that can complement existing testing and inspection methods. We believe that recent trends in both the requirements for software systems and the processes by which systems are developed suggests that domain-specific model checking engines may be more effective than general purpose model checking tools. To overcome limitations of existing tools which tend to be monolithic and non-extensible, we have developed an extensible and customizable model checking framework called Bogor. In this article, we summarize how Bogor provides direct support for modeling object-oriented designs and implementations, how its modeling language and algorithms can be extended and customized to create domain-specific model checking engines, and how Bogor can be deployed in broader software development contexts in conjunction with complementary quality assurance techniques},
  keywords={object-oriented programming;program debugging;program testing;program verification;quality assurance;software quality;Bogor software model checking framework;distributed computing;domain-specific model checking engine creation;multicore architecture;object-oriented design modeling support;object-oriented modeling language;software debugging;software inspection;software model checking tool;software quality assurance technique;software system requirements;software testing;software verification;Computer architecture;Context modeling;Distributed computing;Engines;Hardware;Inspection;Object oriented modeling;Software debugging;Software quality;Software testing},
  doi={10.1109/TAIC-PART.2006.5},
  month={Aug},
}

@INPROCEEDINGS{7163725,
  author={A. Andrianova and V. Itsykson},
  booktitle={2013 Tools Methods of Program Analysis},
  title={Generating unit tests using static analysis and contracts},
  year={2013},
  pages={83-88},
  abstract={Software Quality Assurance is one of the main challenges of software engineering. One of the ways to improve software quality is automated synthesis of unit tests. This paper describes a technology of automated unit tests creation combining the “white” and “black” box approaches. This allows using information extracted from the source code of the program and using partial specifications in the form of contracts to create test oracles and distribute the test parameters across the domain of definition to ensure the test coverage of program paths. The developed approach was implemented as a tool that analyzes Java-based programs and generates test cases for class methods in JUnit format, using CoFoJa to specify the contracts. Testing of the designed tool performed on a number of test objects has proven that the approach is efficient.},
  keywords={Java;contracts;program diagnostics;program testing;software quality;source code (software);CoFoJa;JUnit format;Java-based program;automated software testing;automated synthesis;automated unit test creation;black box approach;contracts;information extraction;software engineering;software quality assurance;source code;static analysis;white box approach;Computational modeling;Computers;Generators;SMT-solver;automated software testing;code analysis;contract-based programming;unit test synthesis},
  doi={10.1109/TMPA.2013.7163725},
  month={Oct},
}

@INPROCEEDINGS{4344093,
  author={X. Deng and Robby and J. Hatcliff},
  booktitle={Testing: Academic and Industrial Conference Practice and Research Techniques - MUTATION (TAICPART-MUTATION 2007)},
  title={Kiasan/KUnit: Automatic Test Case Generation and Analysis Feedback for Open Object-oriented Systems},
  year={2007},
  pages={3-12},
  abstract={We demonstrate how a static analysis feedback and unit test case generation framework, KUnit, built on the Bogor/Kiasan symbolic execution engine provides an effective unit test case generation for sequential heap-intensive Java programs (whose computation structures are incomplete - open systems). KUnit leverages method contract information to better deal with open object-oriented systems and to support automatic mock object creation. To facilitate application to realistic software, KUnit allows the scope/cost of the analysis and test case generation to be controlled via notions of heap configuration coverage. In a broad experimental study on 23 Java data structure modules, we show that it is able to: (a) achieve 100% feasible branch coverage on almost all methods by using only small heap configurations; (b) improve on competing tools for coverage achieved; size of test suites; and time to generate test suites.},
  keywords={Java;automatic test pattern generation;object-oriented programming;open systems;program testing;Bogor/Kiasan symbolic execution engine;Kiasan/KUnit automatic test case generation;automatic mock object creation;open object-oriented system;sequential heap-intensive Java programs;static analysis feedback;Application software;Automatic testing;Contracts;Costs;Engines;Feedback;Java;Open systems;Sequential analysis;System testing},
  doi={10.1109/TAIC.PART.2007.32},
  month={Sept},
}

@ARTICLE{5487640,
  author={O. Tkachuk and M. B. Dwyer},
  journal={IET Software},
  title={Environment generation for validating event-driven software using model checking},
  year={2010},
  volume={4},
  number={3},
  pages={194-209},
  abstract={Event-driven systems maintain an ongoing dialog with their environment. Examples include: distributed programs, where each process reacts to received messages by performing computation and sending messages to peers; graphical user interfaces (GUI), where the interface software and the underlying application react to user inputs and web-based applications, where presentation, business logic and storage tier functionality react to user inputs and response from other web-based services. Such applications are difficult to test because the set of possible interaction sequences between the system and its environment can be very large and governed by complex constraints. The exhaustive nature of software model checking techniques offers hope for effectively validating such systems, however, they only work for closed systems. Previously, the authors developed the Bandera Environment Generator, which given an open system, called a unit under analysis, closes it with a model of its environment. The authors' previous work on environment generation has focused on developing broadly applicable mechanisms for modelling environment behaviour. The generality of this approach often makes it difficult to produce environment models that enable precise and efficient system analysis. The authors' experience shows that by exploiting information about the application domain, generated environments can be made both more precise and more efficient for model checking. This study presents the concept of domain-specific environment generation, details techniques for customising environment generation for the domain of event-driven software, and assesses those techniques on the domains of GUI and web-based applications.},
  keywords={Internet;graphical user interfaces;program testing;program verification;Web-based applications;Web-based services;bandera environment generator;business logic;distributed programs;environment generation;event-driven software validation;graphical user interfaces;interface software;software model checking techniques;storage tier functionality},
  doi={10.1049/iet-sen.2009.0017},
  ISSN={1751-8806},
  month={June},
}

@INPROCEEDINGS{4343944,
  author={X. Deng and J. H. Robby and J. Hatcliff},
  booktitle={Fifth IEEE International Conference on Software Engineering and Formal Methods (SEFM 2007)},
  title={Towards A Case-Optimal Symbolic Execution Algorithm for Analyzing Strong Properties of Object-Oriented Programs},
  year={2007},
  pages={273-282},
  abstract={Recent work has demonstrated that symbolic execution techniques can serve as a basis for formal analysis capable of automatically checking heap-manipulating software components against strong interface specifications. In this paper, we present an enhancement to existing symbolic execution algorithms for object-oriented programs that significantly improves upon the algorithms currently implemented in Bogor/Kiasan and JPF. To motivate and justify the new strategy for handling heap data in our enhanced approach, we present a significant empirical study of the performance of related algorithms and an interesting case counting analysis of the heap shapes that can appear in several widely used Java data structure packages.},
  keywords={Java;object-oriented programming;software packages;Java data structure package;case-optimal symbolic execution algorithm;object-oriented programming;Algorithm design and analysis;Context-aware services;Contracts;Data structures;Information analysis;Java;Packaging;Performance analysis;Shape;Software algorithms},
  doi={10.1109/SEFM.2007.43},
  ISSN={1551-0255},
  month={Sept},
}

@INPROCEEDINGS{7194640,
  author={G. Denaro and A. Margara and M. Pezzè and M. Vivanti},
  booktitle={2015 IEEE/ACM 37th IEEE International Conference on Software Engineering},
  title={Dynamic Data Flow Testing of Object Oriented Systems},
  year={2015},
  volume={1},
  pages={947-958},
  abstract={Data flow testing has recently attracted new interest in the context of testing object oriented systems, since data flow information is well suited to capture relations among the object states, and can thus provide useful information for testing method interactions. Unfortunately, classic data flow testing, which is based on static analysis of the source code, fails to identify many important data flow relations due to the dynamic nature of object oriented systems. In this paper, we propose a new technique to generate test cases for object oriented software. The technique exploits useful inter-procedural data flow information extracted dynamically from execution traces for object oriented systems. The technique is designed to enhance an initial test suite with test cases that exercise complex state based method interactions. The experimental results indicate that dynamic data flow testing can indeed generate test cases that exercise relevant behaviors otherwise missed by both the original test suite and by test suites that satisfy classic data flow criteria.},
  keywords={data flow computing;object-oriented programming;program diagnostics;source code (software);dynamic data flow testing;interprocedural data flow information;object oriented systems;source code;state based method interactions;static analysis;Context;Data models;Object oriented modeling;Object recognition;Performance analysis;Runtime;Testing},
  doi={10.1109/ICSE.2015.104},
  ISSN={0270-5257},
  month={May},
}

@INPROCEEDINGS{6100071,
  author={S. Anand and M. J. Harrold},
  booktitle={2011 26th IEEE/ACM International Conference on Automated Software Engineering (ASE 2011)},
  title={Heap cloning: Enabling dynamic symbolic execution of java programs},
  year={2011},
  pages={33-42},
  abstract={The dynamic symbolic-execution technique can automatically perform symbolic execution of programs that use problematic features of Java, such as native methods. However, to compute precise symbolic execution, the technique requires manual effort to specify models for problematic code. Furthermore, existing approaches to perform symbolic execution either cannot be extended to perform dynamic symbolic execution or incur significant imprecision. In this paper, we present a novel program-transformation technique called heap cloning. Heap cloning transforms a program in such a way that dynamic symbolic execution of the transformed program results in the same path constraints as dynamic symbolic execution of the original program. However, symbolic execution of the transformed program produces feedback on where imprecision is introduced, and that feedback can reduce the manual effort required to build models. Furthermore, such transformation can enable existing approaches to perform symbolic execution systems to overcome their limitations. In this paper, we also present a system, called Cinger, that leverages heap cloning, and that we used to perform an empirical evaluation. The empirical evaluation shows that Cinger can compute precise path constraints, and requires little (if any) manual effort for a set of large real-world programs.},
  keywords={Java;program diagnostics;program interpreters;software performance evaluation;Cinger;Java programs;dynamic symbolic-execution technique;heap cloning;program-analysis technique;program-transformation technique;Cloning;Computational modeling;Concrete;Instruments;Java;Libraries;Manuals},
  doi={10.1109/ASE.2011.6100071},
  ISSN={1938-4300},
  month={Nov},
}

@INPROCEEDINGS{4019612,
  author={Robby and M. B. Dwyer and J. Hatcliff},
  booktitle={21st IEEE/ACM International Conference on Automated Software Engineering (ASE'06)},
  title={Domain-specific Model Checking Using The Bogor Framework},
  year={2006},
  pages={369-370},
  abstract={Model checking has proven to be an effective technology for verification and debugging in hardware and more recently in software domains. We believe that recent trends in both the requirements for software systems and the processes by which systems are developed suggest that domain-specific model checking engines may be more effective than general purpose model checking tools. To overcome limitations of existing tools which tend to be monolithic and non-extensible, we have developed an extensible and customizable model checking framework called Bogor. In this tutorial, we give an overview of (a) Bogor's direct support for modeling object-oriented designs and implementations, (b) its facilities for extending and customizing its modeling language and algorithms to create domain-specific model checking engines, and (c) pedagogical materials that we have developed to describe the construction of model checking tools built on top of the Bogor infrastructure},
  keywords={object-oriented programming;program debugging;program verification;Bogor infrastructure;domain-specific model checking;object-oriented design;program debugging;program verification;software system requirements;Algorithm design and analysis;Context modeling;Dynamic programming;Engines;Java;Object oriented modeling;Power system modeling;Software algorithms;Software systems;Yarn},
  doi={10.1109/ASE.2006.34},
  ISSN={1938-4300},
  month={Sept},
}

@INPROCEEDINGS{6062090,
  author={M. Gligoric and T. Gvero and V. Jagannath and S. Khurshid and V. Kuncak and D. Marinov},
  booktitle={2010 ACM/IEEE 32nd International Conference on Software Engineering},
  title={Test generation through programming in UDITA},
  year={2010},
  volume={1},
  pages={225-234},
  abstract={We present an approach for describing tests using non-deterministic test generation programs. To write such programs, we introduce UDITA, a Java-based language with non-deterministic choice operators and an interface for generating linked structures. We also describe new algorithms that generate concrete tests by efficiently exploring the space of all executions of non-deterministic UDITA programs. We implemented our approach and incorporated it into the official, publicly available repository of Java PathFinder (JPF), a popular tool for verifying Java programs. We evaluate our technique by generating tests for data structures, refactoring engines, and JPF itself. Our experiments show that test generation using UDITA is faster and leads to test descriptions that are easier to write than in previous frameworks. Moreover, the novel execution mechanism of UDITA is essential for making test generation feasible. Using UDITA, we have discovered a number of bugs in Eclipse, NetBeans, Sun javac, and JPF.},
  keywords={Java;data structures;program testing;JPF;Java PathFinder;Java based language;Java programs;UDITA programming;UDITA programs;data structures;test generation;Computer bugs;Concrete;Data structures;Engines;Generators;Java;Testing;Java PathFinder;Pex;UDITA;automated testing;test filtering;test generation;test predicates;test programs},
  doi={10.1145/1806799.1806835},
  ISSN={0270-5257},
  month={May},
}

@inproceedings{Pasareanu:2010:SPS:1858996.1859035,
  author = {P\u{a}s\u{a}reanu, Corina S. and Rungta, Neha},
  title = {Symbolic PathFinder: Symbolic Execution of Java Bytecode},
  booktitle = {Proceedings of the IEEE/ACM International Conference on Automated Software Engineering},
  series = {ASE '10},
  year = {2010},
  isbn = {978-1-4503-0116-9},
  location = {Antwerp, Belgium},
  pages = {179--180},
  numpages = {2},
  url = {http://doi.acm.org/10.1145/1858996.1859035},
  doi = {10.1145/1858996.1859035},
  acmid = {1859035},
  publisher = {ACM},
  address = {New York, NY, USA},
  keywords = {automated test case generation, program analysis},
}

@article{Hillery:2014:TLS:2557833.2560579,
  author = {Hillery, Benjamin and Mercer, Eric and Rungta, Neha and Person, Suzette},
  title = {Towards a Lazier Symbolic Pathfinder},
  journal = {SIGSOFT Softw. Eng. Notes},
  issue_date = {January 2014},
  volume = {39},
  number = {1},
  month = {feb},
  year = {2014},
  issn = {0163-5948},
  pages = {1--5},
  numpages = {5},
  url = {http://doi.acm.org/10.1145/2557833.2560579},
  doi = {10.1145/2557833.2560579},
  acmid = {2560579},
  publisher = {ACM},
  address = {New York, NY, USA},
}

@article{Tidwell:2008:TVD:1366283.1366287,
  author = {Tidwell, Terry and Gill, Christopher},
  title = {Towards Verifiable Deeply Embedded Systems},
  journal = {SIGBED Rev.},
  issue_date = {January 2008},
  volume = {5},
  number = {1},
  month = {jan},
  year = {2008},
  issn = {1551-3688},
  pages = {4:1--4:2},
  articleno = {4},
  numpages = {2},
  url = {http://doi.acm.org/10.1145/1366283.1366287},
  doi = {10.1145/1366283.1366287},
  acmid = {1366287},
  publisher = {ACM},
  address = {New York, NY, USA},
}

@inproceedings{Braione:2016:JSE:2950290.2983940,
  author = {Braione, Pietro and Denaro, Giovanni and Pezz\`{e}, Mauro},
  title = {JBSE: A Symbolic Executor for Java Programs with Complex Heap Inputs},
  booktitle = {Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  series = {FSE 2016},
  year = {2016},
  isbn = {978-1-4503-4218-6},
  location = {Seattle, WA, USA},
  pages = {1018--1022},
  numpages = {5},
  url = {http://doi.acm.org/10.1145/2950290.2983940},
  doi = {10.1145/2950290.2983940},
  acmid = {2983940},
  publisher = {ACM},
  address = {New York, NY, USA},
  keywords = {Alloy, Heap Exploration Logic, Heap data structures, Pointer Assertion Logic, RepOk, Symbolic Execution},
}

@inproceedings{Pasareanu:2008:CUS:1390630.1390635,
  author = {P\v{a}s\v{a}reanu, Corina S. and Mehlitz, Peter C. and Bushnell, David H. and Gundy-Burlet, Karen and Lowry, Michael and Person, Suzette and Pape, Mark},
  title = {Combining Unit-level Symbolic Execution and System-level Concrete Execution for Testing Nasa Software},
  booktitle = {Proceedings of the 2008 International Symposium on Software Testing and Analysis},
  series = {ISSTA '08},
  year = {2008},
  isbn = {978-1-60558-050-0},
  location = {Seattle, WA, USA},
  pages = {15--26},
  numpages = {12},
  url = {http://doi.acm.org/10.1145/1390630.1390635},
  doi = {10.1145/1390630.1390635},
  acmid = {1390635},
  publisher = {ACM},
  address = {New York, NY, USA},
  keywords = {software model checking, symbolic execution, system testing, unit testing},
}

@inproceedings{Robby:2009:PDU:1557898.1557903,
  author = {Robby and Chalin, Patrice},
  title = {Preliminary Design of a Unified JML Representation and Software Infrastructure},
  booktitle = {Proceedings of the 11th International Workshop on Formal Techniques for Java-like Programs},
  series = {FTfJP '09},
  year = {2009},
  isbn = {978-1-60558-540-6},
  location = {Genova, Italy},
  pages = {5:1--5:7},
  articleno = {5},
  numpages = {7},
  url = {http://doi.acm.org/10.1145/1557898.1557903},
  doi = {10.1145/1557898.1557903},
  acmid = {1557903},
  publisher = {ACM},
  address = {New York, NY, USA},
}

@article{King:2009:PAC:1859823.1859830,
  author = {King, Andrew and Procter, Sam and Andresen, Dan and Hatcliff, John and Warren, Steve and Spees, William and Jetley, Raoul and Jones, Paul and Weininger, Sandy},
  title = {A Publish-subscribe Architecture and Component-based Programming Model for Medical Device Interoperability},
  journal = {SIGBED Rev.},
  issue_date = {July 2009},
  volume = {6},
  number = {2},
  month = {jul},
  year = {2009},
  issn = {1551-3688},
  pages = {7:1--7:10},
  articleno = {7},
  numpages = {10},
  url = {http://doi.acm.org/10.1145/1859823.1859830},
  doi = {10.1145/1859823.1859830},
  acmid = {1859830},
  publisher = {ACM},
  address = {New York, NY, USA},
  keywords = {based, component, design, device, interoperability, medical, software, systems},
}

@inproceedings{Braione:2013:ESE:2491411.2491433,
  author = {Braione, Pietro and Denaro, Giovanni and Pezz\`{e}, Mauro},
  title = {Enhancing Symbolic Execution with Built-in Term Rewriting and Constrained Lazy Initialization},
  booktitle = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering},
  series = {ESEC/FSE 2013},
  year = {2013},
  isbn = {978-1-4503-2237-9},
  location = {Saint Petersburg, Russia},
  pages = {411--421},
  numpages = {11},
  url = {http://doi.acm.org/10.1145/2491411.2491433},
  doi = {10.1145/2491411.2491433},
  acmid = {2491433},
  publisher = {ACM},
  address = {New York, NY, USA},
  keywords = {Software analysis, Symbolic execution},
}

@inproceedings{Braione:2015:SEP:2786805.2786842,
  author = {Braione, Pietro and Denaro, Giovanni and Pezz\`{e}, Mauro},
  title = {Symbolic Execution of Programs with Heap Inputs},
  booktitle = {Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering},
  series = {ESEC/FSE 2015},
  year = {2015},
  isbn = {978-1-4503-3675-8},
  location = {Bergamo, Italy},
  pages = {602--613},
  numpages = {12},
  url = {http://doi.acm.org/10.1145/2786805.2786842},
  doi = {10.1145/2786805.2786842},
  acmid = {2786842},
  publisher = {ACM},
  address = {New York, NY, USA},
  keywords = {Symbolic execution, data structure invariants, lazy initialization},
}

@inproceedings{Belt:2009:SLL:1595696.1595762,
  author = {Belt, Jason and Robby and Deng, Xianghua},
  title = {Sireum/Topi LDP: A Lightweight Semi-decision Procedure for Optimizing Symbolic Execution-based Analyses},
  booktitle = {Proceedings of the the 7th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on The Foundations of Software Engineering},
  series = {ESEC/FSE '09},
  year = {2009},
  isbn = {978-1-60558-001-2},
  location = {Amsterdam, The Netherlands},
  pages = {355--364},
  numpages = {10},
  url = {http://doi.acm.org/10.1145/1595696.1595762},
  doi = {10.1145/1595696.1595762},
  acmid = {1595762},
  publisher = {ACM},
  address = {New York, NY, USA},
  keywords = {decision procedure, program analysis, symbolic execution},
}

@article{Distefano:2008:JTP:1449955.1449782,
  author = {Distefano, Dino and Parkinson J, Matthew J.},
  title = {jStar: Towards Practical Verification for Java},
  journal = {SIGPLAN Not.},
  issue_date = {September 2008},
  volume = {43},
  number = {10},
  month = {oct},
  year = {2008},
  issn = {0362-1340},
  pages = {213--226},
  numpages = {14},
  url = {http://doi.acm.org/10.1145/1449955.1449782},
  doi = {10.1145/1449955.1449782},
  acmid = {1449782},
  publisher = {ACM},
  address = {New York, NY, USA},
  keywords = {classes, design patterns, moduarity, separation logic},
}

@inproceedings{Braione:2017:CSE:3092703.3092715,
  author = {Braione, Pietro and Denaro, Giovanni and Mattavelli, Andrea and Pezz\`{e}, Mauro},
  title = {Combining Symbolic Execution and Search-based Testing for Programs with Complex Heap Inputs},
  booktitle = {Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis},
  series = {ISSTA 2017},
  year = {2017},
  isbn = {978-1-4503-5076-1},
  location = {Santa Barbara, CA, USA},
  pages = {90--101},
  numpages = {12},
  url = {http://doi.acm.org/10.1145/3092703.3092715},
  doi = {10.1145/3092703.3092715},
  acmid = {3092715},
  publisher = {ACM},
  address = {New York, NY, USA},
  keywords = {Automatic test case generation, Search-based software engineering, Symbolic execution},
}

@article{Roberson:2010:EMG:1932682.1869461,
  author = {Roberson, Michael and Boyapati, Chandrasekhar},
  title = {Efficient Modular Glass Box Software Model Checking},
  journal = {SIGPLAN Not.},
  issue_date = {October 2010},
  volume = {45},
  number = {10},
  month = {oct},
  year = {2010},
  issn = {0362-1340},
  pages = {4--21},
  numpages = {18},
  url = {http://doi.acm.org/10.1145/1932682.1869461},
  doi = {10.1145/1932682.1869461},
  acmid = {1869461},
  publisher = {ACM},
  address = {New York, NY, USA},
  keywords = {pipal, software model checking},
}

@article{Csallner:2008:DHA:1348250.1348254,
  author = {Csallner, Christoph and Smaragdakis, Yannis and Xie, Tao},
  title = {DSD-Crasher: A Hybrid Analysis Tool for Bug Finding},
  journal = {ACM Trans. Softw. Eng. Methodol.},
  issue_date = {April 2008},
  volume = {17},
  number = {2},
  month = {may},
  year = {2008},
  issn = {1049-331X},
  pages = {8:1--8:37},
  articleno = {8},
  numpages = {37},
  url = {http://doi.acm.org/10.1145/1348250.1348254},
  doi = {10.1145/1348250.1348254},
  acmid = {1348254},
  publisher = {ACM},
  address = {New York, NY, USA},
  keywords = {Automatic testing, bug finding, dynamic analysis, dynamic invariant detection, extended static checking, false positives, static analysis, test case generation, usability},
}
