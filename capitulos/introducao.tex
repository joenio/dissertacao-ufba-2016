\xchapter{Introdução}{}

Observação de métricas de código fonte tem sido uma prática útil em diversos
estudos em engenharia de software, como por exemplo, predição de erros,
visualização de código-fonte, definição e avaliação de intervalos de referência
({\it thresholds}), estimativa de custos e prazos, entre outros.  Métricas tem
sido útil ainda como uma maneira efetiva de se observar a qualidade interna de
produtos de software \cite{Meirelles2013}, uma vez que são bons indicadores de
qualidade \cite{Basili1996}.

%têm sido usadas para  e métricas de complexidade
%de código  podem ser utilizadas para prever a qualidade de software em estágios
%iniciais de desenvolvimento~\cite{Xing2005}.

Medir e compreender aspectos de qualidade interna de software é útil em
atividades de evolução e manutenção, uma vez que a qualidade interna produz
forte impacto nestas atividades, quanto menor a qualidade de código-fonte,
maior será o esforço de mantê-lo \cite{Terceiro2010}. Uma das formas de medir
qualidade interna é em função de métricas de código-fonte, dentre as quais
podemos citar a complexidade estrutural, uma medida que leva em conta a relação
entre acoplamento e coesão dos módulos de um programa \cite{Darcy2005}. Os
autores desta métrica demonstraram por meio de um experimento controlado que
uma alta complexidade estrutural faz projetos de software mais difíceis de
entender, e por isto mesmo, mais difíceis de manter e evoluir.

%, esta
%métrica não está limitada ao paradigma de orientação a objetos e é independente
%de tamanho, ou seja, o tamanho do software não influencia na sua medida.  
%
%Complexidade estrutural representa um aspecto arquitetural importante e envolve
%tanto a organização interna dos módulos quanto a relação entre eles. 

A observação de métricas de código-fonte e as conclusões tomadas a partir
delas, no entando, não podem ser generalizadas uma vez que projetos diferentes
são influenciados por fatores diferentes, de forma que a observação dos
aspectos de qualidade interna devem ser observados e interpretados
separadamente por projeto \cite{Terceiro2012Understanding} ou ao menos por
domínio de aplicação \cite{Meirelles2013}. Dessa forma, pode-se afirmar que
realizar estudos em domínios específicos, especialmente em domínios ainda pouco
estudados são extremamente importantes.

%A análise estática de programas é a atividade de coletar informações de um
%programa de software sem necessidade de execução, é uma atividade presente
%especialmente nas primeiras etapas da compilação, realizando otimizações, ou
%verificações de erros diversos, mas além dos compiladores esta atividade tem
%se mostrado útil em diversas etapas do processo de desenvolvimento,
%especialmente na observação de atributos de qualidade através do monitoramento
%de aspectos qualidade, como por exemplo as métricas de código-fonte.

Diante disso e sabendo que o domínio de aplicação de análise estática carece de
observação detalhada sobre aspectos de qualidade interna de suas ferramentas
podemos concluir que estudos que joguem luz sobre tais aspectos neste domínio
são altamente desejáveis. A área de análise estática de código-fonte tem se
desenvolvido rapidamente com novos métodos, técnicas e ferramentas para os mais
diversos fins, no entanto a comparação e avaliação de técnicas e ferramentas
não tem acompanhado tal velocidade \cite{Li2010}, e, apesar de existirem
estudos avaliando ferramentas de análise estática de código-fonte
\cite{Rutar2004, Kratkiewicz2005, Okun2007, Emanuelsson2008, Wedyan2009,
Mantere2009, Al2010, Li2010, Johns2011, Alemerien2013, Ataide2014}, poucos
fazem isso do ponto de vista de sua qualidade interna, em sua maioria observam
apenas atributos de qualidade externa, como, desempenho, precisão, cobertura de
resultados, entre outros.

%poucos fazem isso do ponto de vista de vista de sua qualidade interna, costumando
%observar tais ferramentas sob a perspectiva de seus usuários, com o foco em seus atributos de qualidade
%externa, como, desempenho, precisão e cobertura de seus resultados.

%Por exemplo, \citeonline{Rutar2004} compara cinco ferramentas de localização
%de bugs para Java e discute as técnicas utilizadas por cada uma e seu impacto
%nos resultados. \citeonline{Kratkiewicz2005} avalia cinco ferramentas de
%análise estática para determinar seus pontos fortes e fracos em detecção de
%falhas de buffer overflow em código C. \citeonline{Okun2007} avalia os efeitos
%de ferramentas de segurança com objetivo de identificar se estas ferramentas
%melhoram de fato a segurança de programas. \citeonline{Emanuelsson2008}
%avaliam três ferramentas de análise estática da indústria com o objetivo de
%mapear funcionalidades significativas destas ferramentas, normalmente não
%fornecidas por compiladores normais. \citeonline{Wedyan2009} avaliaram três
%ferramentas para verificar a efetividade de detectar falhas e predizer
%refatorações. \citeonline{Mantere2009} compararam três ferramentas de análise
%estática de código-fonte em relação à performance e dão subsídios para apoiar
%tomada de decisão sobre seleção de ferramentas de análise estática.
%\citeonline{Al2010} avaliaram quatro ferramentas de análise estática em
%relação à capacidade de detectar bugs em programas concorrentes em Java e
%responde se ferramentas comerciais são melhores que ferramentas {\it open
%source}. \citeonline{Li2010} comparam sete diferentes ferramentas de análise
%estática com foco em detecção de vulnerabilidades, comparando suas
%caracteristicas através de um experimento. \citeonline{Johns2011} avaliaram a
%qualidade de ferramentas de análise estática de segurança a partir de uma
%série de critérios. \citeonline{Alemerien2013} avaliaram duas ferramentas de
%análise estática para cálculo de métricas com objetivo de entender as
%diferenças nos resultados de cada uma. \citeonline{Ataide2014} analisa os
%resultados gerados por três ferramentas de análise estática que podem ser
%eficientemente usadas por programadores para remover vulnerabilidades comuns
%em programas.

%Entretanto, poucos estudos avaliam ferramentas de análise estática de
%código-fonte com foco em sua qualidade interna, considerando o ponto de vista
%de desenvolvedores interessados não apenas em usar, mas também em manter e
%evoluir tais ferramentas. Em tal contexto, surge o problema de identificar,
%medir e analisar fatores técnicos que influenciam na manutenção de uma
%ferramenta de análise estática. Estudos que joguem luz sobre aspectos da
%qualidade interna neste domínio de aplicação são requeridos do ponto de vista
%principalmente dos desenvolvedores interessados em atividades de manutenção e
%evolução.

Observar métricas de código-fonte em nível de projetos de software leva
ao seguinte desafio: como obter valores de métricas que representem todo o projeto sendo
que métricas de código-fonte usualmente são calculadas para cada elemento do sistema, como arquivos ou classes?
Este desafio tem sido amplamente discutido em estudos sobre definição de
intervalos de referência ({\it thresholds}) para métricas de
código-fonte \cite{Shatnawi2010, Kaur2013, Herbold2011}. Intervalos de
referência são valores conhecidos para uma dada medida
\cite[Chapter~2.1]{Lanza2007} com algum valor semantico, por exemplo, se
medirmos a altura das pessoas e definirmos até 2 metros como alto, então
pessoas acima de 2 metros serão classificadas como muito altas.

%Diversos estudos com métricas de código-fonte tem sido conduzidos para avaliar
%a qualidade de um produto de software, entretanto métricas precisam prover
%informações reais e não apenas valores numéricos. Diante disso, muitos estudos
%tem caminhado no sentido de definir intervalos de referência, ou {\it
%thresholds}, para métricas de código-fonte.

Intervalos de referência podem ser definidos de diversas formas, desde
abordagens baseadas em modelos estatísticos \cite{Shatnawi2010, Kaur2013}
até aprendizado de máquina \cite{Herbold2011} e inteligência artificial.
Entre as inúmeras abordagens, muitas partem de estudos empíricos
usando softwares da indústria como objeto de estudo, geralmente com
softwares de domínios específicos, parte-se da coleta de dados de
métricas de código-fonte e com uso de uma abordagem, ou uma combinação entre
elas, chega-se aos intervalos.

Estes intervalos são também continuamente avaliados a fim de saber se são
válidos ou não, as abordagens utilizadas para calcular os intervalos levam em
consideração inúmeros aspectos na tentativa de validar os valores encontrados,
como por exemplo a natureza dos dados, se seguem a lei de distribuição de
potência
\cite{Wheeldon2003,Potanin2005,Concas2007,Ferreira2009,Yao2009,Clauset2009} ou
seguem uma distribuição normal
\cite{Baxter2006,Lanza2007,Herraiz2011,Herraiz2012}, avaliam ainda se possuem
cauda longa, se são livre de escala, entre outros aspectos.

Apesar dos inúmeros estudos sobre métricas e intervalos de referência, e as
várias abordagens utilizadas para validar os valores encontrados, nenhum trabalho
compara tais valores com características arquiteturais,
algo que pode vir a ser útil na compreensão de tais intervalos.
Estudos sobre arquitetura de software tem uma longa e respeitável tradição, a
área emergiu como uma importante disciplina da engenharia de software,
particularmento em atividades de desenvolvimento de grandes sistemas.
Arquitetura dá controle intelectual sobre a complexidade permitindo focar em
partes essenciais do sistema e suas interações, ajudando a compreender como as
diferentes partes de um sistema se relacionam entre sí \cite{Clements2002Book}.

Traçar uma comparação entre intervalos de referência ({\it thresholds}) de
métricas como complexidade estrutural, por exemplo, com métricas que
representam visões arquiteturais de projetos de software pode ser útil como
forma de avaliar se tais medidas estão consistentes entre sí, por exemplo, se
numa dada medida de complexidade estrutural encontra-se valores considerados
ruins indicando problemas arquiteturais, então medidas e métricas relacionadas
arquitetura de software também deveriam confirmar tal indicação.

Dentre os inúmeros estudos sobre arquitetura de software alguns tem feito uso
de uma técnica chamada DSM ({\it Design Structure Matrix}) para observar e
avaliar sistemas complexos, esta técnica foi concebida por
\citeonline{Steward1981} e extendido por \citeonline{Eppinger1991} em um estudo
sobre engenharia concorrente, ela é bastante útil em análises para mapear
sistemas complexos, DSM provê uma representação compacta de um sistema complexo
para visualização de interdependencia entre os seus vários elementos.

DSM tem sido aplicada em diversas áreas do conhecimento, deste gestão de
projetos \cite{Browning2016}, análise de sistemas da engenharia de energia,
automotiva, construção civil, etc. Em engenharia de software alguns estudos
sobre arquitetura de software foram conduzidos para analisar e comparar
estruturas de produtos de software complexos, nestes estudos DSMs são
utilizados para destacar a estrutura do design examinando as dependencias
existentes entre os componentes através de uma matriz simétrica
\cite{Steward1981}. DSM tem sido utilizada também como meio para calcular a
métrica ``custo de mudança'' ({\it Change Cost}) \cite{Maccormack2006},
uma medida para caracterizar a estrutura do design de software a partir da
medida de acoplamento que ela exibe, capturando o nível com qual uma mudança em
um elemento causa de impacto em outras partes do mesmo sitema, seja diretamente
ou indiretamente através de chamadas aninhadas entre os elementos.

A partir disso pode-se dizer que a métrica custo de mudança se mostra bastante
útil em estudos sobre qualidade interna de produtos de software, uma vez que
ela representa características arquiteturais importantes. Além disso, essa
métrica é calculada em nível de projeto e não passa pelos problemas enfrentados
por métricas tradicionais de código-fonte ao serem calculadas em nível de
projeto, como a complexidade estrutural.  Algo que se mostra como uma enorme
oportunidade de estudo sobre o cálculo de intervalos de referência, podendo
servir de base de comparação e apoio na interpretação dos valores encontrados.

Assim, iremos neste trabalho, analisar ferramentas do domínio de análise
estática, extrair as métricas de complexidade estrutural e custo de mudança,
calcular intervalos de referência para a métrica de complexidade estrutural, em
seguida comparar tais intervalos com os valores da métrica custo de mudança a
fim de compreender como estas medidas se comportam neste domínio de aplicação.

%Mas é importante nos questionar: como chegamos ao {\it threshold} 2? Porque não
%1.95m? Porque não 3m? E se uma pessoa tem 2.01 metros, não é pequeno comparado
%com uma pessoa de 2.5 metros?
%
%Inúmeras técnicas tem sido adotadas, uma das mais amplamente
%conhecidas e utilizada é o uso de média e desvio padrão por Lanza, neste método
%é calculada a média dos valores de métricas de cada arquivo/classe de um
%software e partir disso chega-se a um valor único da métrica representando
%o software.
%
%Mas o ponto importante é que não existe intervalos perfeitos, entretanto podemos
%definir intervalos explicáveis, exemplo, valores que podem ser escolhidos com base
%em argumentos adequados. Não são perfeitos mas podem ser úteis na prática, e isto é
%bom o suficiente para alguns propósitos. Podem ser úteis por exemplo para selecionar
%classes para inspeção ou redesign \cite{Rosenberg1998}.
%
%Intervalos de referência podem ser definidos de forma subjetiva, com base na
%experiência do desenvolvedor [CITAR REFS], por meio de abordagens baseadas em
%modelos estatísticos \cite{Shatnawi2010, Kaur2013}, ou ainda por meio de
%abordagens que utilizam aprendizado de máquina\cite{Herbold2011} e inteligência
%artificial 

\cite{Lima2014}

Nas últimas décadas, autores como Alves, Ypma e Visser (2010),
Coppick e Cheatham (1992), Ferreira et al. (2011), Rosenberg, Stapko e Gallo
(1999) e Shatnawi et al. (2010) vêm propondo técnicas e valores de referência
para algumas medidas de software. Há artigos como o de Coppick e Cheatham
(1992), French (1999) e Rosenberg, Stapko e Gallo (1999), que apresentam
valores de referência baseados em “experiência própria” (conhecimento tácito)
sem nenhuma análise estatística ou técnica que suporte a afirmação. No entanto,
uma vez obtidos, em um contexto específico ou sem técnica adequada, os
valores de referência publicados tendem a não ser generalizáveis para além do
contexto de sua obtenção.

%
%Entre as inúmeras propostas, muitas partem de estudos empíricos usando software
%da indústria como objeto de estudo, analisando conjuntos de sistemas de
%software de domínios diferentes, ou mesmo conduzindo estudos longitudinais com
%um único software através do seu histórico de lançamentos. Nestes estudos
%parte-se da coleta de dados de métricas de código-fonte e com uso de uma
%abordagem, ou uma combinação entre elas, chega-se a intervalos de referência.
%
%Inúmeros estudos avaliam a natureza dos dados com objetivo de definir a melhor
%estratégia para calcular tais intervalos de referência, avaliando qual tipo de
%distribuição as métricas de código-fonte de um projeto de software segue.
%
%Muitos estudos sobre métricas de código-fonte têm mostrado que estes dados
%seguem a lei de distribuição de potência \cite{Clauset2009}, em geral com cauda
%longa e grafo livre de escala.  Há estudos que mostram que projetos orientados
%a objetos escritos em Java seguem uma distribuição de lei de potência
%\cite{Wheeldon2003,Potanin2005,Concas2007,Ferreira2009,Yao2009}; outros
%estudos apresentam evidências de que não necessariamente seguem tal
%distribuição \cite{Baxter2006,Lanza2007,Herraiz2011,Herraiz2012}.  Assim,
%não há regra geral para determinar o tipo de distribuição de métricas de
%código-fonte, se seguem as leis de potência de distribuição ou uma distribuição
%normal. 
%
%Muitos trabalhos avaliam estas diversas técnicas, a fim de mostrar se são representativas
%estatisticamente ou não, pois dependendo da natureza dos dados, a média pode ou não ser
%um bom indicador.
%
%Diversos estudos com métricas de código-fonte tem sido conduzidos para avaliar
%a qualidade de um produto de software, entretando métricas precisam prover
%informações reais e não apenas valores numéricos, diante disso muitos estudos
%tem caminhado no sentido de definir intervalos de referência, ou {\it
%thresholds}, para métricas de código-fonte.
%
%Inúmeros estudos avaliam a natureza dos dados com objetivo de definir a melhor
%estratégia para calcular tais intervalos de referência, avaliando qual tipo de
%distribuição as métricas de código-fonte de um projeto de software segue.
%Muitos estudos sobre métricas de código-fonte tem mostrado que estes dados
%seguem a lei de distribuição de potência \cite{Clauset2009}, em geral com calda
%longa e grafo livre de escala. Mas não existe regra geral dizendo qual tipo de
%distribuição métricas de código-fonte pertence, se seguem as leis de potência
%de distribuição ou uma distribuição normal, pois apesar de existirem estudos
%mostrando que projetos orientados a objetos escritos em Java seguem uma
%%distribuição de lei de potência \cite{Wheeldon2003, Potanin2005, Concas2007,
%%Ferreira2009, Yao2009}, outros estudos apresentam evidências de que não
%%necessariamente seguem tal distribuição \cite{Baxter2006, Lanza2007, Herraiz2011, Herraiz2012}.
%
%Com base nisso posso validar se o Change Cost que me diz que uma arquitetura
%eh melhor que outra esta deacordo com as metricas dentro dos intervalos ou nao.
%(ou posso usar apenas CBO que a metrica de acoplamento e Change Cost eh calculada com base em acoplamento)
%
%Se houver tempo de implementar no Analizo Decoupling Level posso usar tb essa metrica pois
%ela eh indepentende de tamanho de acordo com o autor, nao eh sensivel ao tamanho do software.

\section{Questão de pesquisa}

Com este objetivo em mente, levantamos a seguinte questão de pesquisa:

\begin{enumerate}
  \item [{\bf Q1:}] {\em As características das ferramentas de análise estática
  de código-fonte tem impacto em sua manutenabilidade?}
\end{enumerate}

\section{Objetivo geral}

O objetivo principal deste trabalho é compreender as ferramentas de software
para análise estática de código-fonte do ponto de vista de sua
manutenabilidade, a partir da observação de suas características e dos valores
de métricas de código-fonte.

\section{Objetivos específicos}

São objetivos específicos deste trabalho:

\begin{itemize}
  \item Caracterizar as ferramentas de análise estática.
  \item Medir a manutenabilidade das ferramentas de análise estática.
  \item Compreender a relação entre características e manutenabilidade
        das ferramentas de análise estática.
\end{itemize}

\section{Hipóteses} \label{hipoteses}

Para responder a questão colocada acima, definimos as seguintes hipóteses:

\begin{enumerate}
  \item[{\bf H0:}] {\em Não existe correlação entre características das
  ferramentas de análise estática e sua manutenabilidade.}
  \item[{\bf H1:}] {\em Existe correlação entre características das ferramentas
  de análise estática e sua manutenabilidade.}
\end{enumerate}

\section{Contribuições esperadas}

Ao final deste trabalho, as seguintes contribuições científicas ({\bf CC}) e
tecnológicas ({\bf CT}) são esperadas:

(pendente)

%\begin{enumerate}
%  \item [{\bf CC1:}] Um conjunto de intervalos de referência da frequência dos
%    valores de métricas de código-fonte para o domínio de aplicação de
%    análise estática de código-fonte.
%  \item [{\bf CC2:}] Definição de argumentos que expliquem a alta complexidade
%    estrutural em ferramentas de análise estática de código-fonte.
%  \item [{\bf CT1:}] Evolução de uma ferramenta de análise estática de
%    código-fonte.
%\end{enumerate}
%
%Lembrando que neste trabalho serão utilizadas métricas de produto,
%especificamente, métricas de código-fonte, que cobrem aspectos de tamanho,
%complexidade e qualidade.

\section{Estrutura do texto} 

(pendente)

%% O capítulo \ref{fundamentacao} apresenta conceitos sobre análise estática e
%% métricas de código-fonte necessários para compreensão do trabalho. O capítulo
%% \ref{metodologia} apresenta trabalhos relacionados, hipóteses do estudo,
%% planejamento sobre a coleta e análise dos dados
%% e o cronograma do estudo. O capítulo \ref{conclusoes} traz a
%% discussão e interpretação dos dados e apresenta os próximos passos do estudo.
%% 
%% A seção \ref{trabalhos-relacionados} traz trabalhos relacionados à compreensão
%% e observação de atributos de qualidade interna de programas. A seção
%% \ref{hipoteses} detalha como as hipóteses serão testadas. A seção
%% \ref{planejamento} descreve o planejamento de estudo e os passos iniciais de
%% coleta de dados. A seção \ref{coleta} detalha a coleta de dados e a seção
%% \ref{analise} traz informações de como estes dados serão analisados e
%% interpretados.
