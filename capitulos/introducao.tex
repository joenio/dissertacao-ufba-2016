\xchapter{Introdução}{}

% (paulo) Nesta seção manteremos a
%discussão nos argumentos do porquê monitorar métricas de código-fonte, bem como apresentaremos
%as métricas selecionadas (e implementadas) para nossas ferramentas estudos
%
%Qualquer que seja a metodologia de desenvolvimento, monitorar a qualidade do software é
%fundamental. Dentre as inúmeras características que fazem um bom software, várias delas podem
%ser percebidas no código-fonte, e algumas são exclusivas dele.
%
%Métricas de código-fonte foram propostas desde que os primeiros conceitos da engenharia de
%software surgiram. As métricas pioneiras foram rapidamente absorvidas pela indústria, que as usa
%com frequência. Métricas de complexidade e tamanho são as mais usuais, por exemplo LOC (linhas
%de código) e seus derivados (p.ex., erros/LOC, LOC/tempo). Essas métricas são reconhecidamente
%limitadas quando usadas isoladamente. Mas mesmo com o avanço da pesquisa em métricas desde
%então, a indústria continua usando as mesmas métricas simplistas e de forma isolada (Fenton e Neil,
%1999).
%
%Especialistas em métricas podem ser capazes de entender e usar métricas, mas todos desenvolve-
%dores deveriam saber como usá-las para monitorar e melhorar seu código. Facilitar o monitoramento
%pelos desenvolvedores em geral é uma das contribuições desta tese de doutorado ao mostrar (no
%Capítulo 4) como é possível monitorar e estudar um conjunto de métricas de código-fonte de proje-
%tos de software livre e acompanhar a sua evolução. Também, complementando isso, apresentamos
%neste contexto (no Capítulo 5) um conjunto de ferramentas (i.e., uma plataforma) que sistematiza a
%avaliação do código-fonte. Antes de chegarmos nesses pontos, apresentamos em detalhes o conjunto
%de métricas que nortearam os estudos nesta tese.
%
%Em um dos trabalhos mais reconhecidos da área de métricas de código-fonte, (Lanza e Marinescu,
%2006) coletaram diversas métricas de tamanho, complexidade e herança de 45 sistemas feitos em
%Java e 37 em C++. Seus valores são apresentados no livro de sua autoria, que sugere valores consi-
%derados como baixo, médio, alto e muito alto para cada métrica, obtidos através da média e desvio
%padrão dos dados coletados dos sistemas estudados.
%\cite{Lanza2007}
%
% (apresento parte da metodologia)
% apresentar parte da "antiga" metologia aqui
%
%* na introducao coloco questoes de pesquisa, etc, para alcancar os objetivos, usei esta metodologia
%* a outra parte da metodologia será em colcusão ou resultados
%
% Contexto. O contexto faz parte da motivação do trabalho.
% \section{Contexto}
%
% The Detailed Research Methodology which you intend to employ. 
% The methodology section should discuss what methods you are going to use in order 
% to address the research objectives of your dissertation. 
% You need to justify why the chosen methods were selected as the most appropriate 
% for your research, amongst the many alternative ones, given its specific objectives, 
% and constraints you may face in terms of access, time and so on. 
% Reference to general advantages and disadvantages of various methods and techniques 
% without specifying their relevance to your choice decision is unacceptable. 
% Remember to relate the methods back to the needs of your research question. 
%
% Problema. 
% \section{Problema}
% Uma maneira de evidenciar a contribuição do trabalho é 
% definir bem o problema a ser resolvido. 
% Nesse caso, pode-se discutir: o problema em questão, a definição formal 
% do problema e sua importância, relevância, aplicações práticas.
%
% Trabalhos Relacionados. 
% \section{Trabalhos relacionados}
% Outra maneira de evidenciar a contribuição do trabalho 
% é discutir os trabalhos relacionados (resumidamente) ainda na introdução. 
% Esses trabalhos estão no mesmo contexto, não resolvem o problema ou 
% apresentam apenas soluções parciais. 
% Além disso, o trabalho atual pode ser a extensão ou continuação de um trabalho 
% anterior. Nesse caso, o trabalho original deve ser mencionado na introdução.

Observação de métricas de código fonte tem sido uma prática útil em diversos
estudos em engenharia de software, como por exemplo, predição de erros,
visualização de código-fonte através de metáforas visuais, definição e
avaliação de intervalos de referência ({\it thresholds}), estimativa de custos e prazos, entre outros.
Métricas de código-fonte tem sido também utilizadas como uma maneira efetiva
de se observar a qualidade interna de produtos de software \cite{Meirelles2013}
uma vez que são bons indicadores de qualidade \cite{Basili1996}.

%têm sido usadas para  e métricas de complexidade
%de código  podem ser utilizadas para prever a qualidade de software em estágios
%iniciais de desenvolvimento~\cite{Xing2005}.

Medir e compreender aspectos de qualidade interna de software pode ser útil em
atividades de evolução e manutenção, a qualidade interna produz forte impacto
nestas atividades, quanto menor a qualidade de código-fonte, maior será o
esforço de mantê-lo \cite{Terceiro2010}. Uma das formas de medir qualidade
interna é em função de métricas de código-fonte, dentre as quais destaca-se a
métrica de complexidade estrutural, uma medida que leva em conta a relação
entre o acoplamento e coesão dos módulos de um programa \cite{Darcy2005}, esta
métrica não está limitada ao paradigma de orientação a objetos e é independente
de tamanho, ou seja, o tamanho do software não influencia na sua medida.
Os autores desta métrica validaram a suposição de que ela
está associada a maior esforço de manutenção por meio de um
experimento controlado e concluíram que uma alta complexidade estrutural faz
projetos de software mais difíceis de entender, e por isto mesmo, mais difíceis
de manter e evoluir.

%Complexidade estrutural representa um aspecto arquitetural importante e envolve
%tanto a organização interna dos módulos quanto a relação entre eles. 

A observação de métricas de código-fonte e as conclusões tomadas a partir
delas, no entando, não podem ser generalizadas uma vez que projetos diferentes
são influenciados por fatores diferentes, de forma que a observação dos
aspectos de qualidade interna devem ser observados e interpretados
separadamente por projeto \cite{Terceiro2012Understanding} ou ao menos por
domínio de aplicação \cite{Meirelles2013}. Dessa forma, pode-se afirmar que
realizar estudos em domínios específicos, especialmente em domínios ainda pouco
estudados são extremamente importantes.

%A análise estática de programas é a atividade de coletar informações de um
%programa de software sem necessidade de execução, é uma atividade presente
%especialmente nas primeiras etapas da compilação, realizando otimizações, ou
%verificações de erros diversos, mas além dos compiladores esta atividade tem
%se mostrado útil em diversas etapas do processo de desenvolvimento,
%especialmente na observação de atributos de qualidade através do monitoramento
%de aspectos qualidade, como por exemplo as métricas de código-fonte.

Sabe-se portanto que o domínio de aplicação de análise estática carece de observação
detalhada sobre aspectos de qualidade interna de suas ferramentas, a área tem
se desenvolvido rapidamente com novos métodos, técnicas e ferramentas para os
mais diversos fins, no entanto a comparação e avaliação de técnicas e
ferramentas não tem acompanhado tal velocidade \cite{Li2010}, e, apesar de
existirem estudos avaliando ferramentas de análise estática de
código-fonte \cite{Rutar2004, Kratkiewicz2005, Okun2007, Emanuelsson2008,
Wedyan2009, Mantere2009, Al2010, Li2010, Johns2011, Alemerien2013, Ataide2014},
poucos fazem isso do ponto de vista de sua qualidade interna, em sua maioria
observam apenas atributos de qualidade
externa, como, desempenho, precisão, cobertura de resultados, entre outros.

%poucos fazem isso do ponto de vista de vista de sua qualidade interna, costumando
%observar tais ferramentas sob a perspectiva de seus usuários, com o foco em seus atributos de qualidade
%externa, como, desempenho, precisão e cobertura de seus resultados.

%Por exemplo, \citeonline{Rutar2004} compara cinco ferramentas de localização
%de bugs para Java e discute as técnicas utilizadas por cada uma e seu impacto
%nos resultados. \citeonline{Kratkiewicz2005} avalia cinco ferramentas de
%análise estática para determinar seus pontos fortes e fracos em detecção de
%falhas de buffer overflow em código C. \citeonline{Okun2007} avalia os efeitos
%de ferramentas de segurança com objetivo de identificar se estas ferramentas
%melhoram de fato a segurança de programas. \citeonline{Emanuelsson2008}
%avaliam três ferramentas de análise estática da indústria com o objetivo de
%mapear funcionalidades significativas destas ferramentas, normalmente não
%fornecidas por compiladores normais. \citeonline{Wedyan2009} avaliaram três
%ferramentas para verificar a efetividade de detectar falhas e predizer
%refatorações. \citeonline{Mantere2009} compararam três ferramentas de análise
%estática de código-fonte em relação à performance e dão subsídios para apoiar
%tomada de decisão sobre seleção de ferramentas de análise estática.
%\citeonline{Al2010} avaliaram quatro ferramentas de análise estática em
%relação à capacidade de detectar bugs em programas concorrentes em Java e
%responde se ferramentas comerciais são melhores que ferramentas {\it open
%source}. \citeonline{Li2010} comparam sete diferentes ferramentas de análise
%estática com foco em detecção de vulnerabilidades, comparando suas
%caracteristicas através de um experimento. \citeonline{Johns2011} avaliaram a
%qualidade de ferramentas de análise estática de segurança a partir de uma
%série de critérios. \citeonline{Alemerien2013} avaliaram duas ferramentas de
%análise estática para cálculo de métricas com objetivo de entender as
%diferenças nos resultados de cada uma. \citeonline{Ataide2014} analisa os
%resultados gerados por três ferramentas de análise estática que podem ser
%eficientemente usadas por programadores para remover vulnerabilidades comuns
%em programas.

%Entretanto, poucos estudos avaliam ferramentas de análise estática de
%código-fonte com foco em sua qualidade interna, considerando o ponto de vista
%de desenvolvedores interessados não apenas em usar, mas também em manter e
%evoluir tais ferramentas. Em tal contexto, surge o problema de identificar,
%medir e analisar fatores técnicos que influenciam na manutenção de uma
%ferramenta de análise estática. Estudos que joguem luz sobre aspectos da
%qualidade interna neste domínio de aplicação são requeridos do ponto de vista
%principalmente dos desenvolvedores interessados em atividades de manutenção e
%evolução.

Observar métricas de código-fonte em nível de projetos de software leva
ao seguinte desafio: como obter valores de métricas que representem todo o projeto sendo
que métricas de código-fonte usualmente são calculadas para cada elemento do sistema, como arquivos ou classes?
Este desafio tem sido amplamente discutido em estudos sobre definição de
valores ou intervalos de referência ({\it thresholds}) para métricas de
código-fonte \cite{Shatnawi2010, Kaur2013, Herbold2011}. Intervalos de
referência são valores conhecidos para uma dada medida
\cite[Chapter~2.1]{Lanza2007} com algum valor semantico, por exemplo, se
medirmos a altura das pessoas e definirmos até 2 metros como alto, então
pessoas acima de 2 metros serão classificadas como muito altas.

%Diversos estudos com métricas de código-fonte tem sido conduzidos para avaliar
%a qualidade de um produto de software, entretanto métricas precisam prover
%informações reais e não apenas valores numéricos. Diante disso, muitos estudos
%tem caminhado no sentido de definir intervalos de referência, ou {\it
%thresholds}, para métricas de código-fonte.

Intervalos de referência podem ser definidos de diversas formas, desde
abordagens baseadas em modelos estatísticos \cite{Shatnawi2010, Kaur2013}
até aprendizado de máquina \cite{Herbold2011} e inteligência artificial.
Entre as inúmeras abordagens, muitas partem de estudos empíricos
usando softwares da indústria como objeto de estudo, geralmente com
softwares de domínios específicos, parte-se da coleta de dados de
métricas de código-fonte e com uso de uma abordagem, ou uma combinação entre
elas, chega-se aos intervalos.

Estes intervalos são também continuamente avaliados a fim de saber se são
válidos ou não, as abordagens utilizadas para calcular os intervalos levam em
consideração inúmeros aspectos na tentativa de validar os valores
encontrados, como por exemplo a
natureza dos dados, se seguem a lei de distribuição de potência
\cite{Wheeldon2003,Potanin2005,Concas2007,Ferreira2009,Yao2009,Clauset2009} ou
seguem uma distribuição normal
\cite{Baxter2006,Lanza2007,Herraiz2011,Herraiz2012}, avaliam ainda, se possui cauda longa, se são
livre de escala, entre outros aspectos.

No entando, não foram encontrados estudos comparando intervalos de referência
com características arquiteturais de produtos de software, algo que pode ser
útil para compreensão de tais intervalos. Estudos sobre arquitetura de software
tem uma longa e respeitável tradição, a área emergiu como uma importante
disciplina da engenharia de software, particularmento em atividades de
desenvolvimento de grandes sistemas. Arquitetura dá controle intelectual
sobre a complexidade permitindo focar em partes essenciais do sistema e suas
interações, ajudando a compreender como as diferentes partes de um sistema se
relacionam entre sí \cite{Clements2002Book}.

%métricas que representam questões arquiteturais, como complexidade
%estrutural por exemplo, e seus valores de referência podem ser colocados frente
%à frente à 

Traçar uma comparação entre intervalos de referência ({\it thresholds}) de
métricas como complexidade estrutural, por exemplo, com métricas que
representam visões arquiteturais de projetos de software pode ser útil como
forma de avaliar se tais medidas estão consistentes entre sí, por exemplo, se
numa dada medida de complexidade estrutural encontra-se valores considerados
ruins indicando problemas arquiteturais, então medidas e métricas relacionadas
essencialmente a design e arquitetura de software também deveriam confirmar tal
indicação.

Dentre os inúmeros estudos sobre arquitetura de software alguns tem feito uso
de uma técnica chamada DSM ({\it Design Structure Matrix}) para observar e
avaliar sistemas complexos, ela foi concebida por \citeonline{Steward1981} e
extendido por \citeonline{Eppinger1991} em um estudo sobre engenharia
concorrente, útil em análises para mapear sistemas complexos, DSM provê uma
representação compacta de um sistema complexo para visualização de
interdependencia entre os seus vários elementos.

DSM tem sido aplicada em diversas áreas do conhecimento, deste gestão de
projetos \cite{Browning2016}, análise de sistemas da engenharia de energia,
automotiva, construção civil, etc. Em engenharia de software
estudos sobre arquitetura e design de softwares são conduzidos para analisar e
comparar estruturas de produtos de software complexos, DSM
destaca a estrutura do design examinando as dependencias existentes entre
os componentes através de uma matriz simétrica \cite{Steward1981}

Entre os estudos sobre DSM aplicados à arquitetura de software
\citeonline{Maccormack2006} propuseram a métrica ``custo de mudança'' ({\it Change Cost})
para caracterizar a estrutura do design a partir da medida de acoplamento que
ela exibe, capturando o nível com qual uma mudança em um elemento causa impacto
em outros elementos do mesmo sitema, seja diretamente ou indiretamente
através de chamadas aninhadas entre os elementos.

%(potencialmente) 

%{\it Change Cost} é conceitualmente bem próximo à idéia visibilidade
%\cite{Sharman2004}, que por sua vez é construída sobre o conceito de {\it
%reachability matrices} \cite{Warfield1973}. Visibilidade é um conceito
%relacionado à seguinte pergunta: ``Quais outros elementos do sistema devem ser
%reprojetados se este elemento for modificado?''.
%
%Para um grafo dirigido $ G=(V,E) $ com vértices $ i $ e $ j $, seja $ P_ij $
%um caminho direcionado representando $ ij $. Então o grafo:
%
%$ R = ( V(G), { (i,j): i,j in V(G), P_ij in G } ) $
%
%É dito ser um {\it reachability graph} de $ G $, e a matrix adjacente de $ R $
%é dita como $ G $ {\it reachability matrix}.  Vértices adjacentes no {\it
%reachability graph} são conectados por um ou mais caminhos direto no grafo
%original.

Os autores afirmam que esta métrica pode ser aplicada apenas de forma
comparativa, ou seja, não pode-se afirmar que um design específico é ou não
modular, mas sim que um certo design é mais (ou menos) modular que um outro
design. Esta comparação pode ser feita entre produtos de software distintos ou
entre várias versões de um mesmo software.

Apesar da métrica custo de mudança se mostrar bastante útil em estudos sobre
qualidade interna de produtos de software poucos trabalhos fazendo uso de tal
métrica foram encontrados, dentre estes trabalhos nenhum faz uma comparação dos
valores encontrados com outras métricas de código-fonte, usualmente criam
outras métricas a partir do custo de mudança, como é o caso das métricas {\it
relative clustered cost} \cite{Milev2009} e {\it decoupling level}
\cite{Mo2016} propostas para resolver, ambos, o mesmo problema apontado no
custo de mudança, de que custo de mudança é uma métrica sensível ao tamanho do
software em número de arquivos.

Apesar dos problemas apontados no custo de mudança, esta métrica carece de mais
estudos, especialmente estudos que tracem paralelos com outras áreas da
engenharia de software, como é o caso do estudo sobre métricas e intervalos de
referência.

Assim, iremos neste trabalho, analisar ferramentas do domínio de análise
estática, extrair as métricas de complexidade estrutural e custo de mudança,
comparar seus valores sempre partindo do princípio que em designs menos
acoplados a medida de custo de mudança e complexidade estrutural também serão menor.

%O trabalho iniciado na definição da métrica Change Cost gerou alguns desdobramentos,
%\citeonline{Milev2009} baseado no trabalho de cormack Change Cost define uma métrica
%chamada {\it relative clustered cost}. \citeonline{Mo2016} baseado em DSM
%e Design Rules\cite{Baldwin2000} define uma métrica considerada como evolução
%da métrica Change Cost, pois avalia o quanto um dado sistema de software pode
%ser desacoplado, e cria um cálculo indepente do tamanho do software (em linhas
%de código).
%
%\cite{Mo2016} diz que \cite{Maccormack2006} propõe a métrica com o nome
%Propagation Cost (PC) mas o nome proposto por \cite{Maccormack2006} é Change
%Cost, então onde ele cita Propagation Cost está se referindo à Change Cost.
%Neste estudo \cite{Mo2016} mostra que Change Cost é sensível ao número de arquivos
%e nem sempre captura variações arquiteturais.
%
%Decoupling Level (DL) é uma métrica para medir manutenabilidade da arquitetura
%de software. Mede o grau com que uma arquitetura é desacoplada em (pequenas,
%independentes) módulos que podem ser modificadas independentemente por
%desenvolvedores. Altos valores de DL são melhores, indicando uma arquitetura
%mais modular. No entando no estudo realizado notou-se que nem sempre um alto
%valor de DL implica em um projeto de fácil manutenção, alguns dos estudos de caso
%mostraram projetos de difícil manutenabilidade e alto valor de DL.
%
%Custo de mudança ({\it Change Cost})\cite{Maccormack2006} é uma métrica
%de produto de software que indica a possibilidade de impacto que uma
%certa mudança num projeto de software causa no restante do sistema, é
%um indicador de quão custoso é realizar mudanças, mas indicando probabilidades
%apenas.
%
%Esta métrica vem a ser útil para ter uma visão da arquitetura e pode ser
%utilizada para comparar vários software distintos entre sí. Esta é uma métrica
%calculada em nível de projeto, representa o impacto que uma mudança localizada
%em um certo ponto pode causar em outros pontos do mesmo sistema, ele é
%calculado a partir de uma matriz chamada {\it Reachability Matrix}.
%
%Mas é importante nos questionar: como chegamos ao {\it threshold} 2? Porque não
%1.95m? Porque não 3m? E se uma pessoa tem 2.01 metros, não é pequeno comparado
%com uma pessoa de 2.5 metros?
%
%Inúmeras técnicas tem sido adotadas, uma das mais amplamente
%conhecidas e utilizada é o uso de média e desvio padrão por Lanza, neste método
%é calculada a média dos valores de métricas de cada arquivo/classe de um
%software e partir disso chega-se a um valor único da métrica representando
%o software.
%
%Mas o ponto importante é que não existe intervalos perfeitos, entretanto podemos
%definir intervalos explicáveis, exemplo, valores que podem ser escolhidos com base
%em argumentos adequados. Não são perfeitos mas podem ser úteis na prática, e isto é
%bom o suficiente para alguns propósitos. Podem ser úteis por exemplo para selecionar
%classes para inspeção ou redesign \cite{Rosenberg1998}.
%
%Intervalos de referência podem ser definidos de forma subjetiva, com base na
%experiência do desenvolvedor [CITAR REFS], por meio de abordagens baseadas em
%modelos estatísticos \cite{Shatnawi2010, Kaur2013}, ou ainda por meio de
%abordagens que utilizam aprendizado de máquina\cite{Herbold2011} e inteligência
%artificial 
%
%Entre as inúmeras propostas, muitas partem de estudos empíricos usando software
%da indústria como objeto de estudo, analisando conjuntos de sistemas de
%software de domínios diferentes, ou mesmo conduzindo estudos longitudinais com
%um único software através do seu histórico de lançamentos. Nestes estudos
%parte-se da coleta de dados de métricas de código-fonte e com uso de uma
%abordagem, ou uma combinação entre elas, chega-se a intervalos de referência.
%
%Inúmeros estudos avaliam a natureza dos dados com objetivo de definir a melhor
%estratégia para calcular tais intervalos de referência, avaliando qual tipo de
%distribuição as métricas de código-fonte de um projeto de software segue.
%
%Muitos estudos sobre métricas de código-fonte têm mostrado que estes dados
%seguem a lei de distribuição de potência \cite{Clauset2009}, em geral com cauda
%longa e grafo livre de escala.  Há estudos que mostram que projetos orientados
%a objetos escritos em Java seguem uma distribuição de lei de potência
%\cite{Wheeldon2003,Potanin2005,Concas2007,Ferreira2009,Yao2009}; outros
%estudos apresentam evidências de que não necessariamente seguem tal
%distribuição \cite{Baxter2006,Lanza2007,Herraiz2011,Herraiz2012}.  Assim,
%não há regra geral para determinar o tipo de distribuição de métricas de
%código-fonte, se seguem as leis de potência de distribuição ou uma distribuição
%normal. 
%
%Muitos trabalhos avaliam estas diversas técnicas, a fim de mostrar se são representativas
%estatisticamente ou não, pois dependendo da natureza dos dados, a média pode ou não ser
%um bom indicador.
%
%Diversos estudos com métricas de código-fonte tem sido conduzidos para avaliar
%a qualidade de um produto de software, entretando métricas precisam prover
%informações reais e não apenas valores numéricos, diante disso muitos estudos
%tem caminhado no sentido de definir intervalos de referência, ou {\it
%thresholds}, para métricas de código-fonte.
%
%Inúmeros estudos avaliam a natureza dos dados com objetivo de definir a melhor
%estratégia para calcular tais intervalos de referência, avaliando qual tipo de
%distribuição as métricas de código-fonte de um projeto de software segue.
%Muitos estudos sobre métricas de código-fonte tem mostrado que estes dados
%seguem a lei de distribuição de potência \cite{Clauset2009}, em geral com calda
%longa e grafo livre de escala. Mas não existe regra geral dizendo qual tipo de
%distribuição métricas de código-fonte pertence, se seguem as leis de potência
%de distribuição ou uma distribuição normal, pois apesar de existirem estudos
%mostrando que projetos orientados a objetos escritos em Java seguem uma
%%distribuição de lei de potência \cite{Wheeldon2003, Potanin2005, Concas2007,
%%Ferreira2009, Yao2009}, outros estudos apresentam evidências de que não
%%necessariamente seguem tal distribuição \cite{Baxter2006, Lanza2007, Herraiz2011, Herraiz2012}.
%
%Com base nisso posso validar se o Change Cost que me diz que uma arquitetura
%eh melhor que outra esta deacordo com as metricas dentro dos intervalos ou nao.
%(ou posso usar apenas CBO que a metrica de acoplamento e Change Cost eh calculada com base em acoplamento)
%
%Se houver tempo de implementar no Analizo Decoupling Level posso usar tb essa metrica pois
%ela eh indepentende de tamanho de acordo com o autor, nao eh sensivel ao tamanho do software.

\section{Relevância}
% ABAIXO: por que vale a pena tratar analisador estático
% como caso especial? Por que se concentrar nesse domínio?
% Por que abordagens independentes de domínio não atendem?

(pendente)

%%% Estudar ferramentas de análise estática a fim de compreender seus atributos de
%%% qualidade interna e entender quais características %arquiteturais 
%%% explicam tais atributos é de fundamental importância do 
%%% ponto de vista de desenvolvedores interessados
%%% em manter e evoluir ferramentas deste domínio de aplicação.
%%% % sem afetar negativamente seus atributos de qualidade interna.
%%% 
%%% % compreensão, arquitetura;  falar de métricas de produto, valores de referência
%%% A arquitetura de software tem papel importante na compreensão e evolução 
%%% de [ ref ] ...
%%% módulos e dependências entre eles ... coesão e acoplamento entre módulos ...
%%% complexidade estrutural ...
%%%  
%%% Complexidade estrutural crescente em projetos de software pode resultar
%%% no aumento no esforço necessário para atividades de manutenção.
%%% 
%%% A qualidade interna de ferramentas de análise estática pode ser 
%%% por meio de ... métricas de ... 
%%% Valores de referência são importantes ...
%%% Em geral, valores de referência são encontrados para linguagens de programação.
%%% E para domínios?

\subsection{Questão de pesquisa}

Com este objetivo em mente, levantamos a seguinte questão de pesquisa:

\begin{enumerate}
  \item [{\bf Q1:}] {\em Uma maior complexidade estrutural das ferramentas de
  análise estática de código-fonte implicam em um maior custo de mudança?}
\end{enumerate}

% Aim, Main Research Goal
\section{Objetivo geral}

Diante disso, definimos como objetivo principal deste trabalho: compreender
as ferramentas de software para análise estática de código-fonte do ponto de
vista de sua manutenabilidade, a partir da observação e análise de sua complexidade
estrutural e custo de mudança, discutindo quais características arquiteturais
explicam seus atributos de qualidade interna.

% Objectives
\section{Objetivos específicos}

São objetivos específicos deste trabalho:

\begin{itemize}
  \item Caracterizar ferramentas de análise estática com base na revisão
        estruturada da literatura.
  \item Interpretar os valores das métricas de ferramentas de análise estática
        com base nas percepções identificadas na caracterização proposta.
  \item Identificar a relação entre complexidade estrutural e custo de mudança 
        das ferramentas de análise estática.
  \item Avaliar os thresholds encontrados na literatura para métricas de
        código-fonte em relação às métricas calculadas para as ferramentas
        de análise estática.
%  \item Selecionar e obter código-fonte de ferramentas de análise estática
%    desenvolvidas na academia, para coletar suas métricas de código-fonte. A
%    seleção terá como base o resultado de uma revisão estruturada feita a
%    partir de artigos publicados em conferências relacionadas. 
%  \item Selecionar e obter código-fonte de ferramentas de análise estática
%    desenvolvidas pela indústria, para coletar suas métricas de código-fonte.
%  \item Propor intervalos de referência para a observação parametrizada da
%    qualidade interna das ferramentas de análise estática, a partir de suas
%    métricas de código-fonte.
\end{itemize}

\section{Hipóteses} \label{hipoteses}

Para responder a questão colocada acima, definimos as seguintes hipóteses:

\begin{enumerate}
  \item[{\bf H1:}] {\em A complexidade estrutural é alta em ferramentas de
    análise estática de código-fonte com alto valor de custo de mudança.}

  \item[{\bf H2:}] {\em Ferramentas de análise estática com alto número de
    mudanças tem complexidade estrutural e custo de mudança altos.}

  \item[{\bf H3:}] {\em  ...}
    

  \item[{\bf H4:}] {\em Ferramentas de análise estática com maior número de
    classes possuem maior complexidade estrutural e maior custo de mudança.}

  \item[{\bf H5:}] {\em  ...}

\end{enumerate}

(falta explicar como cada hipótese será testada)

%A hipótese {\bf H1} ({\em É possível calcular valores de referência de
%métricas de código-fonte para ferramentas de análise estática a partir de um
%conjunto de softwares da academia e da indústria}) será validada a partir da
%análise das métricas calculadas para cada uma das ferramentas estudadas.  Esta
%análise levará em consideração a caracterização das ferramentas
%(Seção~\ref{caracterizacao-das-ferramentas}), em especial, em um subconjunto
%de ferramentas com melhores valores de métricas.
%
%A hipótese {\bf H2} ({\em Ferramentas de análise estática tendem a ter uma
%maior complexidade estrutural do que ferramentas de outros domínios de
%aplicação}) será validada a partir da comparação com os trabalhos relacionados
%(Seção \ref{trabalhos-relacionados}) que realizaram estudos similares, com
%cálculo e distribuição de métricas, mas que utilizam como objeto de estudo
%conjuntos ferramentas de outros domínios de aplicação.
%
%A hipótese {\bf H3} ({\em Dentre as ferramentas de análise estática de
%código-fonte, aquelas desenvolvidas na indústria apresentam uma menor
%complexidade estrutural}) será validada a partir do cálculo da distância das
%métricas de cada ferramenta com os valores de referências encontrados neste
%estudo (Seção \ref{distancia}).


\section{Contribuições esperadas}

Ao final deste trabalho, as seguintes contribuições científicas ({\bf CC}) e
tecnológicas ({\bf CT}) são esperadas:

(pendente)

%\begin{enumerate}
%  \item [{\bf CC1:}] Um conjunto de intervalos de referência da frequência dos
%    valores de métricas de código-fonte para o domínio de aplicação de
%    análise estática de código-fonte.
%  \item [{\bf CC2:}] Definição de argumentos que expliquem a alta complexidade
%    estrutural em ferramentas de análise estática de código-fonte.
%  \item [{\bf CT1:}] Evolução de uma ferramenta de análise estática de
%    código-fonte.
%\end{enumerate}

Lembrando que neste trabalho serão utilizadas métricas de produto,
especificamente, métricas de código-fonte, que cobrem aspectos de tamanho,
complexidade e qualidade.

\section{Estrutura do texto} 

(pendente)

%% O capítulo \ref{fundamentacao} apresenta conceitos sobre análise estática e
%% métricas de código-fonte necessários para compreensão do trabalho. O capítulo
%% \ref{metodologia} apresenta trabalhos relacionados, hipóteses do estudo,
%% planejamento sobre a coleta e análise dos dados
%% e o cronograma do estudo. O capítulo \ref{conclusoes} traz a
%% discussão e interpretação dos dados e apresenta os próximos passos do estudo.
%% 
%% A seção \ref{trabalhos-relacionados} traz trabalhos relacionados à compreensão
%% e observação de atributos de qualidade interna de programas. A seção
%% \ref{hipoteses} detalha como as hipóteses serão testadas. A seção
%% \ref{planejamento} descreve o planejamento de estudo e os passos iniciais de
%% coleta de dados. A seção \ref{coleta} detalha a coleta de dados e a seção
%% \ref{analise} traz informações de como estes dados serão analisados e
%% interpretados.

%---

%%% %Média não é representativa como se pode observar nas Figuras \ref{fig:histograma-cbo} e \ref{fig:histograma-lcom4}...
%%% 
%%% %% begin.rcode histograma-cbo, fig.align='center', results="asis", fig.cap="distribuição da métrica CBO", fig.width=5, fig.height=3
%%% % histograma('cbo', 'histograma da métrica CBO para todas as ferramentas')
%%% %% end.rcode
%%% 
%%% %% begin.rcode histograma-lcom4, fig.align='center', results="asis", fig.cap="distribuição da métrica LCOM4", fig.width=5, fig.height=3
%%% % histograma('lcom4', 'histograma da métrica LCOM4 para todas as ferramentas')
%%% %% end.rcode
