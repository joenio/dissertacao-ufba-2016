% A Preliminary Literature Review which indicates: 
% (i) that you have studied the work of the major authors in your research field 
% (ii) that you are familiar with the major themes relevant to that subject area 
% (iii) what further investigations you intend to pursue as part of this dissertation. 
% You should bear in mind that you are reviewing the literature in order to develop sharper, 
% more insightful and focused research questions about your topic. 
% Therefore, your literature review should lead to and justify your research objectives and questions.

\xchapter{Fundamentação teórica}
{Este capítulo apresenta conceitos necessários para a compreensão do trabalho.}
\label{fundamentacao}

%À medida que os softwares se tornam uma tecnologia generalizada em praticamente
%todos os aspectos da condição humana, também são inseridos firmemente no meio
%acadêmico, softwares analisam dados, simulam o mundo real, e visualizam
%resultados.

\input{capitulos/ecossistema-de-software-academico.tex}
\input{capitulos/metricas-para-ecossistema-de-software.tex}

%mostrar os beneficios da ciencia aberta, ciberinfraestrutura, etc
%
%(favorecendo a ciencia e tornando a vida mais feliz para todos)
%
%\section{Competição no ecossistema de software acadêmico}
%
%mostrar os problemas para a ciência como um todo
%
%(causando problemas para o progresso de ciência, dados perdidos, etc, retrabalho
%dificuldade de reprodução, etc...)
%
%\input{capitulos/fundamentacao/qualidade-de-software.tex}
%\input{capitulos/fundamentacao/complexidade-de-software.tex}
%\input{capitulos/fundamentacao/analise-estatica.tex}

% , traduzido para software acadêmico para evitar o
% termo {\it software de pesquisa}, a palavra {\it research} em português {\it
% pesquisa} pode ser facilmente confundida com ferramentas ou sistemas de
% pesquisa, como sites de pesquisa por exemplo,
%
% (5) Tools in mining software repositories \cite{chaturvedi2013tools}
%
% Faz uma revisão dos papers submetidos ao MSR desde 2007 até 2013 (?) e
% identifica data sets, ferramentas e técnicas utilizadas pelos autores, mais
% da metade dos papers usam ou criam ferramentas, categoriza as ferramentas em
% ferramentas novas, ferramentas tradicionais, protótipos e scripts para
% mineração de dados
%\item Open Access Pledge \cite{holcombe2011openaccess}\footnote{\url{http://www.openaccesspledge.com}}
%
%  Concentra-se em publicar softwares e papers em locais de {\it open access}.
%
%\item Open Science Peer Review Oath\footnote{\url{https://f1000research.com/articles/3-271/v2}}
%
%  Concentra-se em potencializar os revisores para exigir acesso aberto aos
%  softwares, práticas reprodutíveis e revisões transparentes.
%
%\item UK RSE \cite{ukrse2013}\footnote{\url{http://rse.ac.uk/who}}
%
%  Conscientização sobre a importância e o papel do {\it Research Software
%  Engineer} através de comunicação e suporta institucional.
%
%\item FAIR principles \cite{wilkinson2016fair}\footnote{\url{https://www.nature.com/articles/sdata201618}}
%
%  Foco em dados de pesquisa. O objetivo é fazer eles serem encontráveis,
%  acessíveis, interoperável e reusável. Estes princípios podem ser
%  generalizados para aplicar aos softwares.
%
%\item The GeoScience paper of the future initiative \cite{OntoSoft2016}\footnote{\url{http://www.scientificpaperofthefuture.org/gpf/what-is-a-gpf}}
%
%  Possui um conjunto de requerimentos para softwares serem incluidos em
%  papers.  Focando mais no paper em sí do que no software.
%
%A situação com software é amplamente análoga (mas não identica) ao de dados
%das publicações; de fato, todo dado é processado por softwares de alguma forma
%(Borgman et al., 2012).
%
%
%%%%%%%%%%%%%%%%%%%%%%
%
%Isto contradiz as boas práticas de qualquer projeto experimental ({\it
%laboratory
%notebooks}\footnote{\url{https://en.wikipedia.org/wiki/Lab_notebook}}, dados
%organizados, passos documentados, projeto estruturado para reprodutibilidade) e
%torna praticamente impossível utilizar o método mais comum e cientificamente
%produtivo de produzir conhecimento novo a partir de pesquisas anteriores, a
%replicação, ou seja, seguir os mesmos passos do autor original com
%objetivo de validar, melhorar ou estender seus dados e sua metodologia
%\cite{king1995replication, Stodden2010}.
%
%Saber como cientistas desenvolvem e usam softwares em suas pesquisas é crítico
%para avaliar a necessidade de melhorias no praticas atuais de desenvolvimento e
%para tomar decisões sobre a futura alocação de recursos
%\cite{hannay2009scientists}.
%
%Uma das contribuições chave deste workshop é um manifesto contendo um roteiro
%para o futuro da engenharia de software profissional e acadêmica, com foco em
%instrumentos de suporte para pesquisas em software científico. O manifesto é
%expresso em termos de ações ``promessas'' destinado a usuários e
%desenvolvedores de softwares científicos, com passos concretos para melhorar o
%ambiente em que os softwares são produzidos.
%
%Os compromissos expressados neste manifesto são agrupados em três conceitos gerais:
%(i) garantir que softwares científicos sejam {\it citados} apropriadamente;
%(ii) promover a {\it carreira} do engenheiro de software desenvolvedor de software científico; e
%(iii) medir a qualidade e sustentabilidade do software científico durante e após o seu {\it desenvolvimento}.
%
%No terceiro compromisso, relacionado ao conceito {\it desenvolvimento}, o Dagstuhl Manifesto enfatiza a necessidade de medir a
%qualidade e a sustentabilidade dos softwares científicos, e define
%sustentabilidade de software como capacidade de perdurar, software sustentável
%é aquele que continua a estar disponível no futuro, em novas plataformas e se
%atende às novas necessidades \cite{allen2017engineering}.
%
%Este paper
%apresenta um conjunto de boas práticas que todo pesquisador pode adotar,
%independentemente do seu nível de habilidade em computação. Essas práticas
%passam por gerenciamento de dados, programação, colaboração com colegas,
%organização de projetos, tracking work, e escrita da manuscritos, sao
%desenhados para uma grande variadade de fontes publicadas do noso dia a dia e
%do nosso trabalho como voluntário organizando workshopts desde 2010
%\cite{wilson2017good}.
%
%Diversas maneiras de inventivar citação formal entre artefatos digitais,
%software por exemplo, tem surgido, dentre elas uma iniciativa interessante
%é o Journal of Open Source Software (JOSS) é um livre a open-access jornal para
%publicação de artigos descrevendo software acadêmico. Ele tem dois objetivos
%principais, melhorar a qualidade dos softwares submetidos e prover mecanismos
%para pesquisadores desenvolvedores de software acadêmico receber crédito pelos
%seus softwares. Enquanto pensado para trabalhar dentro do atual sistema de
%mérito da ciência, JOSS visa a escassez de recompensas para contribuições
%importantes para a ciência realizadas em forma de software. JOSS publica
%artigos que encapsulam sabedoria contida no software ele mesmo, e seu rigoroso
%revisão em pares mirado nos componentes do software: funcionalidade,
%documentação, testes, integração contínua, e a licença. Um artigo JOSS contém
%um resumo descrevendo o objetivo e funcionalidades do software, referencias, e
%um link para o software archive.  O artigo é um ponto de entrada para
%submissçao que engloba o conjunto completo de artefatos de software. Artigos
%aceitos no JOSS recebem um digital object identifier (DOI), te seus metadados
%depositados no Crossref, e o artigo pode começar a colecionar citações e ser
%indexados em serviços como Google Scholar e outros. No seu primeiro ano,
%iniciado em Maio de 2016, JOSS publicou 111 artigos, com mais de 40 artigos
%adicionais sob revisão \cite{smith2017journal}.
%
%Linked Open Science—Communicating, Sharing and Evaluating
%Data, Methods and Results for Executable Papers.
%Linked Open Science is an approach to solve challenges of an executable paper. It is a combination of four “silver
%bullets”: 1) publication of scientific data, metadata, results, and provenance information using Linked Data principles,
%2) open source and web-based environments for executing, validating and exploring research, 3) Cloud Computing
%for efficient and distributed computing, and 4) Creative Commons for the legal infrastructure. We will use a realistic
%scientific research setting related to research on deforestation of the Brazilian Amazon rainforest to provide scenarios
%to illustrate the application of Linked Open Science \cite{Kauppinen2011}.
%
%Computer systems research spans sub-disciplines that in-
%clude embedded and real-time systems, compilers, network-
%ing, and operating systems. Our contention is that a number
%of structural factors inhibit quality research. We highlight
%some of the factors we have encountered in our work and ob-
%served in published papers and propose solutions that could
%both increase the productivity of researchers and the quality
%of their output \cite{Vitek2011}.
%
%
%FORCE11 Software Citation principles \cite{smith2016software}\footnote{\url{https://www.force11.org/software-citation-principles}}
%Enfatiza persistencia e claridade e diz que ``Software deve ser considerado
%um produto legítimo de pesquisas e devem ser possível de serem citados''.
%
%o artigo abaixo faz um estudo e usa metrica para calcular o impacto
%das citacoes e mencoes ao software, usa um calculo baseado no numero
%de ocorrencias que o nome do software aparece
%Disciplinary differences of software use and impact in scientific literature
% eu fiz a mesma coisa mas numa avaliação qualitativa, meu peso é, 0 ou 1, menciona o software ou não menciona'
%se menciona, qual tipo, usa, contribui, etc... isto eh que vai dar o valor/peso/metrica
%
%isto, além de fazer os próprios pesquisadores enfrentar problemas ao replicar
%seus próprios trabalhos no futuro, torna quase impossível reproduzir e
%verificar os resultados de pesquisas anteriores, ferindo um dos princípios da
%ciência de que novas descobertas sejam reproduzidas antes de serem consideradas
%parte da base de conhecimento
%
% Best Practices for Scientific Computing \cite{wilson2014best}
% * resume as melhores práticas para melhorar a situação onde softwares
%   academisoc sofrem de manutenabilidade, disponibiliade etc, boas praticas, etc
%
% complemento do artigo acima: 
% Good enough practices in scientific computing \cite{wilson2017good}
%
%  Software Carpentry: lessons learned \cite{wilson2014software}
% (mais uma iniciativa preocupada com as habilidades dos pesquisadores
%  com computacao, esta dificuldae gera pesquisas dificeis de reproduzir,
%  repeticao de trabalho, etc.. licoes aprendidas ao longo de mais de 20 anos)
%
%estas práticas permitem replicar descobertas anteriores seguindo
%o caminho do autor original,
%isto, segundo
%\citeonline{king1995replication}, é o método mais comum e cientificamente
%produtivo de produzir conhecimento novo para a ciência, tanto a ciência quanto
%a engenharia dependem de resultados incrementais para evoluir, no entando,
%
% Replicability is not Reproducibility: Nor is it Good Science
%
% I want to challenge this view by separating
% the notion of reproducibility, a generally de-
% sirable property, from replicability, its poor
% cousin. I claim there are important differ-
% ences between the two. Reproducibility re-
% quires changes; replicability avoids them. Al-
% though reproducibility is desirable, I contend
% that the impoverished version, replicability,
% is one not worth having.
% ...
% In this paper, I have claimed that what many in the
% field are advocating is the replicability of published
% experiments. They argue that this meets the repro-
% ducibility requirement inherent to science. My claim
% is that replicability is a poor substitute for scientific
% reproducibility. There may be other good reasons for
% the collecting of software and scripts that are the ba-
% sis of the experimental results published in papers but
% scientific reproducibility is not one.
%
%The lack of replicability and reproducibility of scientific studies based on
%computational methods has lead to serious mistakes in published scientific
%findings, some of which have been discovered and publicized recently. Many
%strategies are currently pursued to improve the situation. This article reports the
%first conclusions from the ActivePapers project, whose goal is the development
%and application of a computational platform that allows the publication of
%computational research in a form that enables installation-free deployment,
%encourages reuse, and permits the full integration of datasets and software into
%the scientific record. The main finding is that these goals can be achieved with
%existing technology, but that there is no straightforward way to adapt legacy
%software to such a framework \cite{hinsen2014activepapers}
%
%Reproducibility verification is essential to the practice of the scientific method.
%Researchers report their findings, which are strengthened as other independent groups
%in the scientific community share similar outcomes. In the many scientific fields
%where software has become a fundamental tool for capturing and analyzing data, this
%requirement of reproducibility implies that reliable and comprehensive software platforms
%and tools should be made available to the scientific community. The tools will empower
%them and the public to verify, through practice, the reproducibility of observations that
%are reported in the scientific literature. Medical image analysis is one of the fields in
%which the use of computational resources, both software and hardware, are an essential
%platform for performing experimental work. In this arena, the introduction of the Insight
%Toolkit (ITK) in 1999 has transformed the field and facilitates its progress by accelerating
%the rate at which algorithmic implementations are developed, tested, disseminated and
%improved. By building on the efficiency and quality of open source methodologies, ITK has
%provided the medical image community with an effective platform on which to build a daily
%workflow that incorporates the true scientific practices of reproducibility verification. This
%article describes the multiple tools, methodologies, and practices that the ITK community
%has adopted, refined, and followed during the past decade, in order to become one of the
%research communities with the most modern reproducibility verification infrastructure. For
%example, 207 contributors have created over 2400 unit tests that provide over 84% code
%line test coverage. The Insight Journal, an open publication journal associated with the
%toolkit, has seen over 360,000 publication downloads. The median normalized closeness
%centrality, a measure of knowledge flow, resulting from the distributed peer code review
%system was high, 0.46 \cite{McCormick2014}.
%
%Among empirical software engineering studies, those based on data re-
%trieved from development repositories (such as those of source code management,
%issue tracking or communication systems) are specially suitable for reproduction.
%However their reproducibility status can vary a lot, from easy to almost impossible
%to reproduce. This paper explores which elements can be considered to characterize
%the reproducibility of a study in this area, and how they can be analyzed to better
%understand the type of reproduction studies they enable or obstruct. One of the
%main results of this exploration is the need of a systematic approach to asses the
%reproducibility of a study, due to the complexity of the processes usually involved,
%and the many details to be taken into account. To address this need, a methodology
%for assessing the reproducibility of studies is also presented and discussed, as a tool to
%help to raise awareness about research reproducibility in this field. The application
%of the methodology in practice has shown how, even for papers aimed to be
%reproducible, a systematic analysis raises important aspects that render reproduction
%difficult or impossible. We also show how, by identifying elements and attributes
%related to reproducibility, it can be better understood which kind of reproduction
%can be done for a specific study, given the description of datasets, methodologies and
%parameters it uses \cite{gonzalez2012reproducibility}.
%
%Science rests on peer review and the wide-spread dissemination of
%knowledge. Software engineering research will advance further and
%faster if the sharing of data and tools were easier and more wide-
%spread. Pragmatic concerns hinder the realization of this ideal: the
%time and effort required and the risk of being scooped. We examine
%the costs and benefits of facilitating sharing in our field in an effort
%to help the community understand what problems exist and find
%a solution. We examine how other fields, such as medicine and
%physics, handle sharing, describe the value of sharing for replication
%and innovation, and address practical concerns such as standards
%and warehousing. To launch what we hope will become an ongoing
%discussion of solutions in our community, we present some ways
%forward that mitigate the risk of sharing — partial sharing, registry,
%escrow, and market \cite{barr2010shoulders}.
%
%At various machine learning conferences, at
%various times, there have been discussions
%arising from the inability to replicate the
%experimental results published in a paper.
%There seems to be a wide spread view that we
%need to do something to address this prob-
%lem, as it is essential to the advancement
%of our field. The most compelling argument
%would seem to be that reproducibility of ex-
%perimental results is the hallmark of science.
%Therefore, given that most of us regard ma-
%chine learning as a scientific discipline, being
%able to replicate experiments is paramount.
%I want to challenge this view by separating
%the notion of reproducibility, a generally de-
%sirable property, from replicability, its poor
%cousin. I claim there are important differ-
%ences between the two. Reproducibility re-
%quires changes; replicability avoids them. Al-
%though reproducibility is desirable, I contend
%that the impoverished version, replicability,
%is one not worth having \cite{drummond2009replicability}.
%
%Abstract—This paper is the result of reviewing all papers
%published in the proceedings of the former International
%Workshop on Mining Software Repositories (MSR) (2004-2006)
%and now Working Conference on MSR (2007-2009). We have
%analyzed the papers that contained any experimental analysis
%of software projects for their potentiality of being replicated.
%In this regard, three main issues have been addressed: i) the
%public availability of the data used as case study, ii) the public
%availability of the processed dataset used by researchers and iii)
%the public availability of the tools and scripts. A total number of
%171 papers have been analyzed from the six workshops/working
%conferences up to date. Results show that MSR authors use
%in general publicly available data sources, mainly from free
%software repositories, but that the amount of publicly available
%processed datasets is very low. Regarding tools and scripts, for
%a majority of papers we have not been able to find any tool,
%even for papers where the authors explicitly state that they have
%built one. Lessons learned from the experience of reviewing the
%whole MSR literature and some potential solutions to lower the
%barriers of replicability are finally presented and discussed
%\cite{robles2010replicating}.
%
% A survey of controlled experiments in software engineering
%
% Among
% the 20 replications, five can be considered as close replica-
% tions in the terminology of Lindsay and Ehrenberg [31], i.e.,
% one attempts to retain, as much as is possible, most of the
% known conditions of the original experiment.
%
% Replication of empirical studies in software engineering: Preliminary findings from a systematic mapping study
%
% The number of replications grew in the last few years, but the
% absolute number of replications is still very small, in particular
% considering the breadth of topics in software engineering. Incentive
% to perform external replications and better standards to report
% empirical studies and their replications are still needed.
%
%% O surgimento do conteito de engenharia de software baseada em envidências (EBSE
%% - {\it Evidence-Based Software Engineering }) surgiu em um trabalho seminal
%% apresentado em 2004 na {\it International Conference on Software Engineering
%% (ICSE)} e suas ideias e ferramentas, especialmente a revisão sistemática, tem
%% evoluído e amadurecido ao longo do tempo, e tem ajudado a caracterizar e
%% consolidar nosso conhecimento sobre muitos aspectos da pesquisa e práticas da
%% engenharia de software.
%% 
%% Em engenharia de software o termo {\it literatura} foi adicionado formando
%% revisão sistemática de literatura, isto foi feito para evitar confusão com
%% práticas de inspeção de código (comumente definido com o termo revisão) existentes
%% na área.
%% 
%% O objetivo de uma revisão sistemática é buscar e identificar todo material relevante
%% relacionado a um certo tópico (a natureza deste material é determinada pelas
%% questões de pesquisa e a natureza dos participantes intererssados na pesquisa).
%% 
%% Um fator em favor da aceitação dos conceitos da EBSE tem sido a crescente
%% reconhecimento que os resultados de estudos empíricos individuais são frequentemente
%% inconclusivos, e estes tipo de estudos são difícels de replicar com sucesso
%% \cite{sjoberg2005survey}.
%% 
%% Ainda existem poucos estudos replicados \cite{kitchenham2015evidence}.
%
% Em resumo os dois manifestos, Dagstuhl e Karlskrona, exprimem o conceito de
% sustentabilidade necessários para este estudo, mas é importante citar que
% algumas iniciativas e outros manifestos também estão preocupados com questões
% similares, dentre os quais podemos destacar:
% 
%A ciência aberta e comunidades de pesquisa em software tem sido bastante ativas
%em criar manifestos visando chamadas para ação. Estes manifestos chamam para melhorar
%os softwares e os metadados de bibliografia para citação persistente destes softwares.
%Outros tópicos endereçados nestes manifestos incluem ênfase no acesso ao código fonte.
%
%ganhando atenção da comunidade devido ao papel que ocupam na reprodutibilidade
%de seus estudos \cite{Peng2011}.
%
%reflexão tem mostrado, por exemplo, que muitos estudos em engenharia de
%software sofrem de dificuldades de repetição \cite{Tang2016}, e apontam
%problemas específicos relacionados à manutenabilidade e a sustentabilidade
%técnica dos softwares acadêmicos.
%
% ao falar de ecossistema seria bom citar o evento da ufba de tools onde o analizo já foi apresentado
%
% Academic Software Development Tools and Techniques
% resumo de um evento local para apresentacao de ferramentas academicas criadas com OO
% (esse é uma prática para incentivar colaboração e promover os projetos)
% uma das ferramentas que enontrei esta apresentado nesse paper, Rigi
%
%isto leva a um corpo computacional
%extramente difícil de reproduzir uma vez que mais da metade dos pesquisadores
%desenvolvem seus próprios softwares \cite{hettrick_2014_14809}, além de ferir um dos
%fundamentos da ciência de que novas descobertas sejam reproduzidas antes de
%serem consideradas parte da base de conhecimento \cite{Stodden2009}.
%
%A comunidade tem refletido sobre os problemas relacionados ao
%desenvolvimento, promoção e sustentabilidade desses softwares, e o
%impacto que tais problemas causam no meio científico \cite{allen2017engineering}. Esta
%reflexão tem mostrado, por exemplo, que muitos estudos em engenharia de
%software sofrem de dificuldades de repetição \cite{Tang2016}, e apontam
%problemas específicos relacionados à manutenabilidade e a sustentabilidade
%técnica dos softwares acadêmicos.
%
% Software Sustainability: The Modern Tower of Babel
% campos da engenharia de software, e apesar dos inúmeros entendimentos sobre o
% conceito \cite{venters2014software}, 
%
%Muitos pesquisadores não
%disponibilizam os seus softwares \cite{robles2010replicating,
%amann2015software} ou quanto o fazem enfrentam problemas com disponibilidade e
%manutenabilidade \cite{Prlic2012},
%
%Pesquisadores de
%software podem contribuir identificando questões de pesquisa em seu campo para
%ajudar a melhor entender sustentabilidade em projetos de software, Discutir com
%seus pares e pensar sobre como sustentabilidade impacta sua área de pesquisa.
%%   \item Reproducibility manifesto \cite{Barba2012}\footnote{\url{http://lorenabarba.com/gallery/reproducibility-pi-manifesto}}
%% 
%%     Inclui termos para fazer softwares reusáveis por outros. Foco em
%%     reprodutibilidade, deixando sustentabilidade de software fora de questão.
% 
%Somado a isto temos ainda o fato de que pesquisadores raramente publicam seus
%códigos, piorando ainda mais toda a situação, isto tem motivado a organização
%de conferências específicas para discutir os problemas dos softwares
%acadêmicos, como o RSE (Conference of Research Software Engineers)\footnote{
%\url{http://rse.ac.uk/conf2017}}, WSSSPE (Workshop on Sustainable Software for
%Science: Practice and Experiences)\footnote{
%\url{http://wssspe.researchcomputing.org.uk}} e o RESER (Workshop on
%Replication in Empirical Software Engineering Research)\footnote{
%\url{http://sequoia.cs.byu.edu/reser}}, e tem agregado discussões das
%comunidades de ciência aberta, reprodutibilidade e sustentabilidade de
%software.
%
%A ciência caminha sob a teoria e experimentação \cite{vardi2010science}. Não existe ciência fechada.
%
%À medida que os softwares se tornam uma tecnologia generalizada em praticmente
%todos os aspectos da condição humana, também é inserida firmemente no meio
%acadêmico. Em particular, na ciência da computação e, nas pesquisas da engenharia de
%software, softwares e conjuntos de ferramentas experimentais emergem
%continuamente, como parte da produção do esforço de pesquisa ou como parte do
%método de pesquisa.
%
%Há uma explosão de dados abertos disponíveis on-line que é acessado e analisado
%através da criação de um novo software - gerando mais dados para analisar. Os
%softwares, ou seja, qualquer software que adquira, limpe, armazene, anote,
%transforme, filtre, gere (etc.) dados de pesquisa.
%
%artigo mostra o decaimento das URLs ao longo do tempo, fundamenta o assunto,
%mostra grafico com o caimento ao longo dos anos
%Use it or lose it: citations predict the continued online
%availability of published bioinformatics resources
%outro grafico muito foda do estudo acima é cruzar o efeito das citacoes
%por ano na availability rate (tenho dados suficiente para fazer um grafico igual)
%
%, não apenas técnica, mas também a
%capacidade de ser encontrado, compartilhado e co-desenvolvido, qualidades
%importantes para a evolução do próprio software, mas também extremamente útil
%para um uso eficiente dos limitados recursos da ciência \cite{howison2013,
%katz2014transitive}.
%
%contradizendo as boas
%práticas de qualquer projeto experimental, de ter {\it laboratory
%notebooks}\footnote{\url{https://en.wikipedia.org/wiki/Lab_notebook}}, dados
%organizados, passos documentados, e projeto estruturado para reprodutibilidade.
%
%softwares acadêmicos, assim
%como qualquer outro aparato experimental, são tão importantes para a ciência
%quanto são os telescópios ou tubos de ensaio \cite{wilson2014best}.
%
%Cientistas gastam mais tempo hoje utilizando e desenvolvendo softwares do que
%gastavam no passado.
%
%
%que um pacote de recursos humanos ou de
%contabilidade deve fazer, e eles sentem que podem entender (talvez com algum
%esforço) os requisitos desses pacotes.
%
%, em ciência da computação,
%particularmente em engenharia de software, tem-se notado um aumento constante
%no número de novos softwares acadêmicos \cite{allen2017engineering}.
%
%Software is a critical part of modern research and yet there is little support across the
%scholarly ecosystem for its acknowledgement and citation. Inspired by the activities
%of the FORCE11 working group focused on data citation, this document
%summarizes the recommendations of the FORCE11 Software Citation Working
%Group and its activities between June 2015 and April 2016. Based on a review of
%existing community practices, the goal of the working group was to produce a
%consolidated set of citation principles that may encourage broad adoption of a
%consistent policy for software citation across disciplines and venues. Our work is
%presented here as a set of software citation principles, a discussion of the motivations
%for developing the principles, reviews of existing community practice, and a
%discussion of the requirements these principles would place upon different
%stakeholders. Working examples and possible technical solutions for how these
%principles can be implemented will be discussed in a separate paper.
%\cite{smith2016software}
%
%; entre 15\% e
%29\% dos softwares são inacessíveis, apenas entre 24\% e 40\% fornecem código
%fonte.
%
%
%Agências de financiamento como o {\it US National Science Foundation} estão começando
%a reconhecer produtos de pesquisa como software assim como fazem com as publicações.
%Isto reconhece as contribuições ao softwares assim como primeiro produto de pesquisa.
%
%O {\it Journal of the American Statistical Association (JASA)} irá agora insistir na
%disponibilidade do código e dados durante a revisão dos manuscritos \cite{baker2016scientists}.
%
%Softwares que não geram,
%processam ou analisam dados ou resultados - como por exemplo, editores de texto
%ou navegadores web - não são considerados softwares acadêmicos, segundo esta
%definição.
%
%Isto se torna ainda mais difícil visto que frequentemente os pesquisadores
%deixam de publicar o código dos seus softwares acadêmicos argumentando que o
%código é ``ruim'' e isto irá gerar julgamentos negativos ao pesquisador
%\cite{allen2017engineering}.
%
%este artigo \cite{howison2016software} faz exatamento o mesmo estudo que estou fazendo!
%A well-functioning system
%would assist not only the goals of understanding and trans-
%parency, but also the goals of aiding replication (Stodden
%et al., 2010), complementing the availability of publications
%such that “the second researcher will receive all the benefits
%of the first researcher’s hard work” (King, 1995, p. 445).
%
% Improving academic software engineering projects: A comparative study of academic and industry projects
% (compara as praticas de desenvolvimento da industria e academia e sugere melhorias, 1998!)
% https://link.springer.com/article/10.1023%2FA%3A1018925902814?LI=true
